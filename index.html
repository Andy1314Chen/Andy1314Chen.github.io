<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
	<meta name="google-site-verification" content="y1NE4TYCS_y-0LIIks73rI2qINI9JYRwk6Su8ZG-ZIw" />
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Life, Books, Code" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta property="og:type" content="website">
<meta property="og:title" content="Andy&#39;s blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Andy&#39;s blog">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Andy&#39;s blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Andy's blog</title>
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  
<a href="https://github.com/Andy1314Chen.github.io"><img style="position: absolute; top: 0; left: 0; border: 0;" src="https://camo.githubusercontent.com/82b228a3648bf44fc1163ef44c62fcc60081495e/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f6c6566745f7265645f6161303030302e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_left_red_aa0000.png"></a>
  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Andy's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">每天进步一点儿</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/08/30/Windows下安装Xgboost/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Andy Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Andy's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/30/Windows下安装Xgboost/" itemprop="url">Windows系统下Xgboost安装【转】</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-30T12:37:43+08:00">
                2017-08-30
              </time>
            

            

            
          </span>

		  
		  
          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
			
			
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>XGBoost是Gradient Boosting算法的一种高级实现，在Kaggle competitions上崭露头角。下面就对XGBoost在Windows上的安装作一个介绍，因为XGBoost在Windows平台上的安装不是那么简单直接。我在实验室的电脑上（Windows 7，64 bits）通过这些步骤安装成功，希望能对后来人有所帮助。</p>
<p><img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR7eIqfJRaX1uWf9oLGlL-3BT2qR2lswhzWj_psFGKy8xgKvJbs" alt=""></p>
<h2 id="安装必要的软件"><a href="#安装必要的软件" class="headerlink" title="安装必要的软件"></a>安装必要的软件</h2><p>为了能在Windows上通过Python使用XGBoost，需要先安装以下三个软件：</p>
<ul>
<li>Python</li>
<li>Git</li>
<li>MINGW</li>
</ul>
<h2 id="Python和Git的安装"><a href="#Python和Git的安装" class="headerlink" title="Python和Git的安装"></a>Python和Git的安装</h2><p>对于Python，你可以到Python官网上下载你想安装的版本，安装很简单，这里就跳过。对于Git的安装有很多种选择，一种选择就是使用Git for Windows，Git for Windows的安装也比较简单，遵从指示就行，这里也跳过。</p>
<h2 id="XGBoost的下载"><a href="#XGBoost的下载" class="headerlink" title="XGBoost的下载"></a>XGBoost的下载</h2><p>Git安装完成后，开始菜单中会出现一个叫Git Bash的程序，点开后就会出现一个类似Windows命令行的窗口，首先在这个Bash窗口，使用cd命令进入你想保存XGBoost代码的文件夹，比如下面的示例：</p>
<pre><code>$ cd /e/algorithm
</code></pre><p>然后输入下面的代码下载XGBoost文件包：</p>
<pre><code>$ git clone --recursive https://github.com/dmlc/xgboost
$ cd xgboost
$ git submodule init
$ git submodule update
</code></pre><h2 id="编译XGBoost代码"><a href="#编译XGBoost代码" class="headerlink" title="编译XGBoost代码"></a>编译XGBoost代码</h2><h3 id="MinGW-W64的安装"><a href="#MinGW-W64的安装" class="headerlink" title="MinGW-W64的安装"></a>MinGW-W64的安装</h3><p>接下来就是编译我们刚刚下载的XGBoost的代码。这就需要用到MinGW-W64。它的安装包我是从这里下载的，下载完成后双击安装，出现下面的安装界面，点击Next：</p>
<p><img src="http://o9zemtn5i.bkt.clouddn.com/mingw_1.JPG" alt=""></p>
<p>然后<strong>在Architecture选项处选择x86_64</strong>(!!!不要忘记了)即可，其他选项保持默认，如下图：</p>
<p><img src="http://o9zemtn5i.bkt.clouddn.com/mingw_2.JPG" alt=""></p>
<p>然后点击下一步，就能安装完成。我使用的是默认安装路径C:\Program Files\mingw-w64\x86_64-6.3.0-posix-seh-rt_v5-rev1。那么make命令和运行库就在下面的文件夹中（也就是包含mingw32-make的文件夹）：C:\Program Files\mingw-w64\x86_64-6.3.0-posix-seh-rt_v5-rev1\mingw64\bin，接下来就是把上面的路径添加到系统的Path中，关于如何添加环境变量到系统的Path中，可以参考<a href="https://www.computerhope.com/issues/ch000549.htm" target="_blank" rel="external">这篇文章</a>。</p>
<p>上面的步骤完成后，关闭Git Bash窗口后重新打开，为了确认添加环境变量已经添加成功，可以在Bash中键入下面的命令：</p>
<pre><code>$ which mingw32-make
</code></pre><p>如果添加成功的话，应该返回类似下面这样的信息：</p>
<pre><code>C:\Program Files\mingw-w64\x86_64-6.3.0-posix-seh-rt_v5-rev1\mingw64\bin\mingw32-make
</code></pre><p>为了输入的方便，可以简化mingw32-make命令为make</p>
<pre><code>$ alias make=&apos;mingw32-make&apos;
</code></pre><h3 id="XGBoost的编译"><a href="#XGBoost的编译" class="headerlink" title="XGBoost的编译"></a>XGBoost的编译</h3><p>现在就可以开始编译XGBoost了，首先进入xgboost文件夹</p>
<pre><code>$ cd /e/algorithm/xgboost
</code></pre><p>通过<a href="https://xgboost.readthedocs.io/en/latest/build.html#building-on-windows" target="_blank" rel="external">这篇官方文档</a>给出的统一编译的方法在写这篇文章时还不能正常编译成功，所以我们采用下面的命令来分开编译，每次编译一个子模块。注意，我们要等每个命令编译完成后才能键入下一个命令。</p>
<pre><code>$ cd dmlc-core
$ make -j4
$ cd ../rabit
$ make lib/librabit_empty.a -j4
$ cd ..
$ cp make/mingw64.mk config.mk
$ make -j4
</code></pre><p>一旦最后一个命令完成后，整个编译过程就完成了。下面就开始安装Python模块。进入XGBoost文件夹下面的python-package子文件夹，然后键入：</p>
<pre><code>$ cd /e/algorithm/xgboost/python-package&gt;python setup.py install
</code></pre><p>进行到这儿，基本上就完成了，这时打开一个Jupyter notebook，直接导入xgboost包会出现错误，我们需要先运行下面的代码：</p>
<pre><code>import os
mingw_path = &apos;C:\Program Files\mingw-w64\x86_64-6.3.0-posix-seh-rt_v5-rev1\mingw64\bin&apos;
os.environ[&apos;PATH&apos;] = mingw_path + &apos;;&apos; + os.environ[&apos;PATH&apos;]
</code></pre><h3 id="成功示例"><a href="#成功示例" class="headerlink" title="成功示例"></a>成功示例</h3><p>然后我们就可以开始导入xgboost包去运行下面的示例：</p>
<pre><code>import xgboost as xgb
import numpy as np
data = np.random.rand(5,10) # 5 entities, each contains 10 features
label = np.random.randint(2, size=5) # binary target
dtrain = xgb.DMatrix( data, label=label)
dtest = dtrain
param = {&apos;bst:max_depth&apos;:2, &apos;bst:eta&apos;:1, &apos;silent&apos;:1, &apos;objective&apos;:&apos;binary:logistic&apos; }
param[&apos;nthread&apos;] = 4
param[&apos;eval_metric&apos;] = &apos;auc&apos;
evallist  = [(dtest,&apos;eval&apos;), (dtrain,&apos;train&apos;)]
num_round = 10
bst = xgb.train( param, dtrain, num_round, evallist )
bst.dump_model(&apos;dump.raw.txt&apos;)
</code></pre><p>至此，如果没有出现错误，就表示安装成功。</p>
<h2 id="附加"><a href="#附加" class="headerlink" title="附加"></a>附加</h2><ol>
<li>可能对git bash不熟悉的可以先看看git操作命令</li>
<li>上面添加PATH步骤很重要，有些网上的博客并未提及，我第一次就是这里没有安装成功</li>
<li>xgboost这个文件夹最好不要放在python的工作路径内，也不要随意删除</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a href="https://wang-shuo.github.io/2017/02/21/%E5%9C%A8Windows%E4%B8%8B%E5%AE%89%E8%A3%85XGBoost/" target="_blank" rel="external">https://wang-shuo.github.io/2017/02/21/%E5%9C%A8Windows%E4%B8%8B%E5%AE%89%E8%A3%85XGBoost/</a></li>
<li><a href="https://www.ibm.com/developerworks/community/blogs/jfp/entry/Installing_XGBoost_For_Anaconda_on_Windows?lang=en" target="_blank" rel="external">https://www.ibm.com/developerworks/community/blogs/jfp/entry/Installing_XGBoost_For_Anaconda_on_Windows?lang=en</a></li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/08/25/windows系统与树莓派间文件传输/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Andy Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Andy's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/25/windows系统与树莓派间文件传输/" itemprop="url">Windows系统与树莓派间文件传输</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-25T00:00:00+08:00">
                2017-08-25
              </time>
            

            

            
          </span>

		  
		  
          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/树莓派3/" itemprop="url" rel="index">
                    <span itemprop="name">树莓派3</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/树莓派3/好记性不如烂笔头/" itemprop="url" rel="index">
                    <span itemprop="name">好记性不如烂笔头</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
			
			
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>windows系统和树莓派之间文件传输方式有很多种，利用FileZilla来传输，是我用的最简便快捷的一种。</p>
<h3 id="FileZilla特点"><a href="#FileZilla特点" class="headerlink" title="FileZilla特点"></a>FileZilla特点</h3><ol>
<li>易于使用</li>
</ol>
<blockquote>
<p>FileZilla比其他任何一款FTP软件都要简单</p>
</blockquote>
<ol>
<li>多协议支持</li>
</ol>
<blockquote>
<p>FileZilla支持FTP、FTPS、SFTP等文件传输协议</p>
</blockquote>
<ol>
<li>多种语言</li>
</ol>
<blockquote>
<p>FileZilla支持多国语言，完美支持简体中文</p>
</blockquote>
<ol>
<li>多标签界面</li>
</ol>
<blockquote>
<p>多标签界面</p>
</blockquote>
<ol>
<li>远程查找文件</li>
</ol>
<blockquote>
<p>FileZilla支持远程查找文件功能</p>
</blockquote>
<ol>
<li>站点管理器</li>
</ol>
<blockquote>
<p>FileZilla自带功能强大的站点管理和传输队列管理</p>
</blockquote>
<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>虽然介绍的功能比较多，但我关心的是与树莓派的文件传输功能。</p>
<p>直接上图：</p>
<p><img src="http://i.imgur.com/ofIVqB2.jpg" alt=""></p>
<ol>
<li>主机：<strong>sftp://YOUR DEVICE IP ADDRESS(192.168.1.102)</strong></li>
<li>填写用户名和密码，端口可不填</li>
<li><strong>快速连接</strong></li>
</ol>
<p>左边<strong>本底站点</strong>为你的windows系统资源管理器，右边<strong>远程站点</strong>是树莓派文件系统，直接拖拽就可以实现文件传输。<br><em>需要注意的是有些树莓派中的文件是有访问等级的，可能无法操作</em></p>
<p>下载地址：<a href="https://filezilla-project.org/" target="_blank" rel="external">FileZilla - The free FTP solution</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/08/22/ReliefF特征选择(python)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Andy Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Andy's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/22/ReliefF特征选择(python)/" itemprop="url">Relief特征选择算法Python实现</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-22T00:00:00+08:00">
                2017-08-22
              </time>
            

            

            
          </span>

		  
		  
          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/算法/" itemprop="url" rel="index">
                    <span itemprop="name">算法</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
			
			
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Relief算法"><a href="#Relief算法" class="headerlink" title="Relief算法"></a>Relief算法</h2><p>Relief算法最早由Kira在1992年提出，最初局限于两类数据的分类问题。Relief算法是一种特征权重算法(Feature weighting algorithms)，根据各个特征和类别的相关性赋予特征不同的权重，权重小于某个阈值的特征将被移除。Relief算法中特征和类别的相关性是基于特征对近距离样本的区分能力。</p>
<p><img src="https://www.gia.edu/images/Gold-Diggers-195648-636x358.jpg" alt="特征提取"></p>
<p><strong>基本思想：</strong>算法从训练集D中随机选择一个样本R，然后从和R同类的样本中寻找最近邻样本H，称为NearHit，从和R不同类的样本中寻找最近邻样本M，称为NearMiss，然后根据以下规则更新每个特征的权重：如果R和NearHit在某个特征上的距离小于R和NearMiss上的距离，则说明该特征对区分同类和不同类的最近邻是有益的，则增加该特征的权重；反之，如果R和NearHit在某个特征的距离大于R和NearMiss上的距离，说明该特征对区分同类和不同类的最近邻起负面作用，则降低该特征的权重。以上过程重复m次，最后得到各特征的平均权重。特征的权重越大，表示该特征的分类能力越强，反之，表示该特征分类能力越弱。Relief算法的运行时间随着样本的抽样次数m和原始特征个数N的增加线性增加，因而运行效率非常高。</p>
<p><strong>具体算法：</strong></p>
<p><img src="http://images.cnitblog.com/blog/79603/201308/29173431-34ed1713754f42e9a875eaa2e4049f8e.jpg" alt="Relief具体算法"></p>
<h2 id="ReliefF算法"><a href="#ReliefF算法" class="headerlink" title="ReliefF算法"></a>ReliefF算法</h2><p>虽然Relief算法比较简单，但运行效率高，并且结果也比较令人满意，因此得到广泛应用，但是其局限性在于只能处理两类别数据，因此1994年Kononeill对其进行了扩展，得到了ReliefF算法，可以处理多类别问题。ReliefF算法在处理多类问题时，每次从训练样本集中随机取出一个样本R，然后从和R同类的样本集中找出R的k个近邻样本(near Hits)，从每个R的不同类的样本集中均找出k个近邻样本(near Misses)，然后更新每个特征的权重，如下式所示：</p>
<p><img src="http://images.cnitblog.com/blog/79603/201308/29173617-b9db490cd1b84472a5583ac52d3df72b.jpg" alt=""></p>
<p><img src="http://images.cnitblog.com/blog/79603/201308/29173649-320dfe76b46e4c1097edb518dacea888.jpg" alt=""></p>
<h2 id="ReliefF算法python程序"><a href="#ReliefF算法python程序" class="headerlink" title="ReliefF算法python程序"></a>ReliefF算法python程序</h2><pre><code>import numpy as np
from sklearn.metrics.pairwise import pairwise_distances
def reliefF(X,y,**kwargs):
   if &quot;k&quot; not in kwargs.keys():
        k=5
   else:
        k=kwargs[&quot;k&quot;]
n_samples,n_features=X.shape

#计算两两距离，曼哈顿距离
distance=pairwise_distances(X,metric=&apos;manhattan&apos;)

score=np.zeros(n_features)

for idx in range(n_samples):
    #同类最近邻
    near_hit=[]
    #异类最近邻
    near_miss=dict()

    self_fea=X[idx,:]
    #类别数
    c=np.unique(y).tolist()

    stop_dict=dict()
    for label in c:
        stop_dict[label]=0
    del c[c.index(y[idx])]

    P_dict=dict()
    p_label_idx=float(len(y[y==y[idx]]))/float(n_samples)

    for label in c:
        p_label_c=float(len(y[y==label]))/float(n_samples)
        p_dict[label]=p_label_c/(1-p_label_idx)
        near_miss[label]=[]

    distance_sort=[]
    distance[idx,idx]=np.max(distance[idx,:])

    for i in range(n_samples):
            distance_sort.append([distance[idx,i],int(i),y[i]])
    distance_sort.sort(key=lambda x: x[0])

    for i in range(n_samples):
        #找到同类最近邻
        if distance_sort[i][2]==y[idx]:
            if len(near_hit) &lt;k:
                near_hit.append(distance_sort[i][1])
            elif len(near_hit)==k:
                stop_dict[y[idx]]=1
        else:
        #异类最近邻
            if len(near_miss[distance_sort[i][2])&lt;k:
                near_miss[distance_sort[i][2].append(distance_sort[i][1])
            else:
                if len(near_miss[distance_sort[i][2]]) == k:
                    stop_dict[distance_sort[i][2]] = 1
        stop = True
        for (key, value) in stop_dict.items():
                if value != 1:
                    stop = False
        if stop:
            break

    #更新reliefF分数
    for ele in near_hit:
        near_hit_term = np.array(abs(self_fea-X[ele, :]))+np.array(near_hit_term)

    near_miss_term = dict()
    for (label, miss_list) in near_miss.items():
        near_miss_term[label] = np.zeros(n_features)
        for ele in miss_list:
            near_miss_term[label] = np.array(abs(self_fea-X[ele, :]))+np.array(near_miss_term[label])
        score += near_miss_term[label]/(k*p_dict[label])
    score -= near_hit_term/k
return score

def feature_ranking(score):
    idx = np.argsort(score, 0)
    return idx[::-1]
</code></pre><p>参考博文：</p>
<ol>
<li><a href="http://www.cnblogs.com/asxinyu/archive/2013/08/29/3289682.html" target="_blank" rel="external">http://www.cnblogs.com/asxinyu/archive/2013/08/29/3289682.html</a></li>
<li><a href="https://github.com/jundongl/scikit-feature" target="_blank" rel="external">https://github.com/jundongl/scikit-feature</a></li>
</ol>
<p>特征提取Python库：<br><a href="http://featureselection.asu.edu/" target="_blank" rel="external">http://featureselection.asu.edu/</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/08/17/机器学习书单/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Andy Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Andy's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/17/机器学习书单/" itemprop="url">机器学习路线【转】</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-17T00:00:00+08:00">
                2017-08-17
              </time>
            

            

            
          </span>

		  
		  
          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/book/" itemprop="url" rel="index">
                    <span itemprop="name">book</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/book/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
			
			
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h2><ul>
<li><a href="#preparation">前言</a> </li>
<li><a href="#curriculum">课程列表</a></li>
<li><p><a href="#learning_route">推荐学习路线</a></p>
<ul>
<li><a href="#math_basic">数学基础初级</a></li>
<li><a href="#programming_basic">程序语言能力</a> </li>
<li><a href="#machine_learning_basic">机器学习课程初级</a></li>
<li><a href="#math_median">数学基础中级</a></li>
<li><a href="#machine_learning_median">机器学习课程中级</a></li>
</ul>
</li>
<li><p><a href="#booklists">推荐书籍列表</a></p>
</li>
<li><a href="#special_learning">机器学习专项领域学习</a></li>
<li><a href="#many_thanks">致谢</a></li>
</ul>
<p><img src="http://i.imgur.com/WDsQmWN.jpg" alt="Machine Learning"></p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><h2 id="preparation">前言</h2></h2><p>   我们要求把这些课程的所有Notes,Slides以及作者强烈推荐的论文看懂看明白，并完成所有的老师布置的习题，而推荐的书籍是不做要求的，如果有些书籍是需要看完的，我们会进行额外的说明。</p>
<h2 id="课程列表"><a href="#课程列表" class="headerlink" title="课程列表"></a><h2 id="curriculum">课程列表</h2></h2><table>
<thead>
<tr>
<th style="text-align:left">课程</th>
<th style="text-align:center">机构</th>
<th style="text-align:center">参考书</th>
<th style="text-align:center">Notes等其他资料</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="http://open.163.com/movie/2006/8/M/L/M6GLI5A07_M6GLJH1ML.html" target="_blank" rel="external">单变量微积分</a></td>
<td style="text-align:center">MIT</td>
<td style="text-align:center"><a href="https://www.amazon.com/exec/obidos/ASIN/0070576424/ref=nosim/mitopencourse-20" target="_blank" rel="external">Calculus with Analytic Geometry</a></td>
<td style="text-align:center"><a href="https://ocw.mit.edu/courses/mathematics/18-01-single-variable-calculus-fall-2006/" target="_blank" rel="external">链接</a> </td>
</tr>
<tr>
<td style="text-align:left"><a href="http://open.163.com/special/opencourse/multivariable.html" target="_blank" rel="external">多变量微积分</a></td>
<td style="text-align:center">MIT</td>
<td style="text-align:center"><a href="https://www.amazon.com/exec/obidos/ASIN/0130339679/ref=nosim/mitopencourse-20" target="_blank" rel="external">Multivariable Calculus</a></td>
<td style="text-align:center"><a href="https://ocw.mit.edu/courses/mathematics/18-02-multivariable-calculus-fall-2007/" target="_blank" rel="external">链接</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://open.163.com/special/opencourse/daishu.html" target="_blank" rel="external">线性代数</a></td>
<td style="text-align:center">MIT</td>
<td style="text-align:center"><a href="http://math.mit.edu/~gs/linearalgebra/" target="_blank" rel="external">Introduction to Linear Algebra</a></td>
<td style="text-align:center"><a href="https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/study-materials/" target="_blank" rel="external">链接</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://open.163.com/movie/2011/6/6/0/M82IC6GQU_M83J9IK60.html" target="_blank" rel="external">统计入门</a></td>
<td style="text-align:center">可汗学院</td>
<td style="text-align:center">暂无</td>
<td style="text-align:center">暂无</td>
</tr>
<tr>
<td style="text-align:left">概率论入门: <a href="http://mooc.guokr.com/course/461/%E6%A9%9F%E7%8E%87/" target="_blank" rel="external">链接1</a>,<a href="https://www.youtube.com/watch?v=GwSEguqJj6U&amp;index=1&amp;list=PLtvno3VRDR_jMAJcNY1n4pnP5kXtPOmVk" target="_blank" rel="external">链接2</a></td>
<td style="text-align:center">NTU</td>
<td style="text-align:center">暂无</td>
<td style="text-align:center">暂无</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://www.youtube.com/watch?v=j9WZyLZCBzs&amp;list=PLQ3khvAsNhargDx0dG1cQXOrA2u3JsFKc" target="_blank" rel="external">概率与统计</a></td>
<td style="text-align:center">MIT</td>
<td style="text-align:center"><a href="https://www.amazon.com/exec/obidos/ASIN/188652923X/ref=nosim/mitopencourse-20" target="_blank" rel="external">Introduction to Probability</a></td>
<td style="text-align:center"><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041-probabilistic-systems-analysis-and-applied-probability-fall-2010/tutorials/" target="_blank" rel="external">链接</a></td>
</tr>
<tr>
<td style="text-align:left">矩阵论</td>
<td style="text-align:center">暂无</td>
<td style="text-align:center"><a href="https://www.amazon.cn/%E7%9F%A9%E9%98%B5%E8%AE%BA-%E6%88%B4%E5%8D%8E/dp/B00116BRO0/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1478614198&amp;sr=1-1&amp;keywords=%E6%88%B4%E5%8D%8E%EF%BC%8C+%E7%9F%A9%E9%98%B5%E8%AE%BA" target="_blank" rel="external">矩阵论</a></td>
<td style="text-align:center">暂无 </td>
</tr>
<tr>
<td style="text-align:left"><a href="https://lagunita.stanford.edu/courses/Engineering/CVX101/Winter2014/about" target="_blank" rel="external">凸优化1</a></td>
<td style="text-align:center">Stanford</td>
<td style="text-align:center"><a href="http://www.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf" target="_blank" rel="external">Convex Optimization</a></td>
<td style="text-align:center"><a href="http://stanford.edu/class/ee364a/index.html" target="_blank" rel="external">链接</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="https://www.youtube.com/watch?v=U3lJAObbMFI&amp;list=PL3940DD956CDF0622&amp;index=20" target="_blank" rel="external">凸优化2</a></td>
<td style="text-align:center">Stanford</td>
<td style="text-align:center">暂无</td>
<td style="text-align:center"><a href="http://stanford.edu/class/ee364b/" target="_blank" rel="external">链接</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/about" target="_blank" rel="external">统计学习入门</a></td>
<td style="text-align:center">Stanford</td>
<td style="text-align:center"><a href="http://www-bcf.usc.edu/~gareth/ISL/" target="_blank" rel="external">An Introduction to Statistical Learning</a></td>
<td style="text-align:center"><a href="https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/about" target="_blank" rel="external">链接</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="https://www.coursera.org/instructor/htlin" target="_blank" rel="external">机器学习基石</a></td>
<td style="text-align:center">NTU</td>
<td style="text-align:center"><a href="https://www.amazon.com/gp/product/1600490069" target="_blank" rel="external">Learning from Data</a></td>
<td style="text-align:center"><a href="https://www.csie.ntu.edu.tw/~htlin/course/mlfound16fall/" target="_blank" rel="external">链接</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="https://www.coursera.org/instructor/htlin" target="_blank" rel="external">机器学习技法</a></td>
<td style="text-align:center">NTU</td>
<td style="text-align:center">暂无</td>
<td style="text-align:center"><a href="https://www.csie.ntu.edu.tw/~htlin/course/ml15fall/" target="_blank" rel="external">链接</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="https://www.youtube.com/watch?v=mbyG85GZ0PI&amp;index=1&amp;list=PLD63A284B7615313A" target="_blank" rel="external">机器学习</a></td>
<td style="text-align:center">Caltech</td>
<td style="text-align:center"><a href="https://www.amazon.com/gp/product/1600490069" target="_blank" rel="external">Learning from Data</a></td>
<td style="text-align:center"><a href="http://work.caltech.edu/lectures.html" target="_blank" rel="external">链接</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://open.163.com/movie/2008/1/M/C/M6SGF6VB4_M6SGHFBMC.html" target="_blank" rel="external">机器学习(matlab)</a></td>
<td style="text-align:center">Stanford</td>
<td style="text-align:center">暂无</td>
<td style="text-align:center"><a href="http://cs229.stanford.edu/materials.html" target="_blank" rel="external">链接</a></td>
</tr>
<tr>
<td style="text-align:left">Python程序语言设计</td>
<td style="text-align:center">暂无</td>
<td style="text-align:center">暂无</td>
<td style="text-align:center">暂无</td>
</tr>
<tr>
<td style="text-align:left">Matlab程序语言设计</td>
<td style="text-align:center">暂无</td>
<td style="text-align:center">暂无</td>
<td style="text-align:center">暂无</td>
</tr>
</tbody>
</table>
<h2 id="推荐学习路线"><a href="#推荐学习路线" class="headerlink" title="推荐学习路线"></a><h2 id="learning_route">推荐学习路线</h2></h2><h3 id="数学基础初级"><a href="#数学基础初级" class="headerlink" title="数学基础初级"></a><h3 id="math_basic">数学基础初级</h3></h3><table>
<thead>
<tr>
<th style="text-align:left">课程</th>
<th style="text-align:center">机构</th>
<th style="text-align:center">参考书</th>
<th style="text-align:center">Notes等其他资料</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="http://open.163.com/movie/2006/8/M/L/M6GLI5A07_M6GLJH1ML.html" target="_blank" rel="external">单变量微积分</a></td>
<td style="text-align:center">MIT</td>
<td style="text-align:center"><a href="https://www.amazon.com/exec/obidos/ASIN/0070576424/ref=nosim/mitopencourse-20" target="_blank" rel="external">Calculus with Analytic Geometry</a></td>
<td style="text-align:center"><a href="https://ocw.mit.edu/courses/mathematics/18-01-single-variable-calculus-fall-2006/" target="_blank" rel="external">链接</a> </td>
</tr>
<tr>
<td style="text-align:left"><a href="http://open.163.com/special/opencourse/multivariable.html" target="_blank" rel="external">多变量微积分</a></td>
<td style="text-align:center">MIT</td>
<td style="text-align:center"><a href="https://www.amazon.com/exec/obidos/ASIN/0130339679/ref=nosim/mitopencourse-20" target="_blank" rel="external">Multivariable Calculus</a></td>
<td style="text-align:center"><a href="https://ocw.mit.edu/courses/mathematics/18-02-multivariable-calculus-fall-2007/" target="_blank" rel="external">链接</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://open.163.com/special/opencourse/daishu.html" target="_blank" rel="external">线性代数</a></td>
<td style="text-align:center">MIT</td>
<td style="text-align:center"><a href="http://math.mit.edu/~gs/linearalgebra/" target="_blank" rel="external">Introduction to Linear Algebra</a></td>
<td style="text-align:center"><a href="https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/study-materials/" target="_blank" rel="external">链接</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://open.163.com/movie/2011/6/6/0/M82IC6GQU_M83J9IK60.html" target="_blank" rel="external">统计入门</a></td>
<td style="text-align:center">可汗学院</td>
<td style="text-align:center">暂无</td>
<td style="text-align:center">暂无</td>
</tr>
<tr>
<td style="text-align:left">概率论入门: <a href="http://mooc.guokr.com/course/461/%E6%A9%9F%E7%8E%87/" target="_blank" rel="external">链接1</a>,<a href="https://www.youtube.com/watch?v=GwSEguqJj6U&amp;index=1&amp;list=PLtvno3VRDR_jMAJcNY1n4pnP5kXtPOmVk" target="_blank" rel="external">链接2</a></td>
<td style="text-align:center">NTU</td>
<td style="text-align:center">暂无</td>
<td style="text-align:center">暂无</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://www.youtube.com/watch?v=j9WZyLZCBzs&amp;list=PLQ3khvAsNhargDx0dG1cQXOrA2u3JsFKc" target="_blank" rel="external">概率与统计</a></td>
<td style="text-align:center">MIT</td>
<td style="text-align:center"><a href="https://www.amazon.com/exec/obidos/ASIN/188652923X/ref=nosim/mitopencourse-20" target="_blank" rel="external">Introduction to Probability</a></td>
<td style="text-align:center"><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041-probabilistic-systems-analysis-and-applied-probability-fall-2010/tutorials/" target="_blank" rel="external">链接</a></td>
</tr>
</tbody>
</table>
<h3 id="程序语言能力"><a href="#程序语言能力" class="headerlink" title="程序语言能力"></a><h3 id="programming_basic">程序语言能力</h3></h3><p>考虑到机器学习的核心是里面的数学原理和算法思想，程序语言目前主要是帮助大家较好的完成课后作业以及实现自己的一些idea，此处我们仅仅给出推荐的参考学习链接，大家掌握一些常用的模块即可，即完成参考学习链接部分的内容即可，推荐书籍比较经典，但不做要求。</p>
<table>
<thead>
<tr>
<th style="text-align:left">课程</th>
<th style="text-align:center">参考学习链接</th>
<th style="text-align:center">推荐书籍</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Python程序语言设计</td>
<td style="text-align:center"><a href="http://cs231n.github.io/python-numpy-tutorial/" target="_blank" rel="external">链接</a></td>
<td style="text-align:center">暂无  </td>
</tr>
<tr>
<td style="text-align:left">Matlab程序语言设计</td>
<td style="text-align:center">暂无</td>
<td style="text-align:center">暂无 </td>
</tr>
<tr>
<td style="text-align:left">R程序语言设计</td>
<td style="text-align:center">暂无</td>
<td style="text-align:center">暂无 </td>
</tr>
</tbody>
</table>
<h3 id="机器学习课程初级"><a href="#机器学习课程初级" class="headerlink" title="机器学习课程初级"></a><h3 id="machine_learning_basic">机器学习课程初级</h3></h3><table>
<thead>
<tr>
<th style="text-align:left">课程</th>
<th style="text-align:center">机构</th>
<th style="text-align:center">参考书</th>
<th style="text-align:center">Notes等其他资料</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/about" target="_blank" rel="external">统计学习入门</a></td>
<td style="text-align:center">Stanford</td>
<td style="text-align:center"><a href="http://www-bcf.usc.edu/~gareth/ISL/" target="_blank" rel="external">An Introduction to Statistical Learning</a></td>
<td style="text-align:center"><a href="https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/about" target="_blank" rel="external">链接</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="external">机器学习入门</a></td>
<td style="text-align:center">Coursera</td>
<td style="text-align:center">暂无</td>
<td style="text-align:center"><a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="external">链接</a></td>
</tr>
</tbody>
</table>
<h3 id="数学基础中级"><a href="#数学基础中级" class="headerlink" title="数学基础中级"></a><h3 id="math_median">数学基础中级</h3></h3><table>
<thead>
<tr>
<th style="text-align:left">课程</th>
<th style="text-align:center">机构</th>
<th style="text-align:center">参考书</th>
<th style="text-align:center">Notes等其他资料</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">矩阵论</td>
<td style="text-align:center">暂无</td>
<td style="text-align:center"><a href="https://www.amazon.cn/%E7%9F%A9%E9%98%B5%E8%AE%BA-%E6%88%B4%E5%8D%8E/dp/B00116BRO0/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1478614198&amp;sr=1-1&amp;keywords=%E6%88%B4%E5%8D%8E%EF%BC%8C+%E7%9F%A9%E9%98%B5%E8%AE%BA" target="_blank" rel="external">矩阵论</a></td>
<td style="text-align:center">暂无 </td>
</tr>
<tr>
<td style="text-align:left"><a href="https://lagunita.stanford.edu/courses/Engineering/CVX101/Winter2014/about" target="_blank" rel="external">凸优化1</a></td>
<td style="text-align:center">Stanford</td>
<td style="text-align:center"><a href="http://www.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf" target="_blank" rel="external">Convex Optimization</a></td>
<td style="text-align:center"><a href="http://stanford.edu/class/ee364a/index.html" target="_blank" rel="external">链接</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="https://www.youtube.com/watch?v=U3lJAObbMFI&amp;list=PL3940DD956CDF0622&amp;index=20" target="_blank" rel="external">凸优化2</a></td>
<td style="text-align:center">Stanford</td>
<td style="text-align:center">暂无</td>
<td style="text-align:center"><a href="http://stanford.edu/class/ee364b/" target="_blank" rel="external">链接</a></td>
</tr>
</tbody>
</table>
<p>下面这个概述必须看完。</p>
<ul>
<li><a href="https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1405.4980" target="_blank" rel="external">Convex Optimization: Algorithms and Complexity</a></li>
</ul>
<h3 id="机器学习课程中级"><a href="#机器学习课程中级" class="headerlink" title="机器学习课程中级"></a><h3 id="machine_learning_median">机器学习课程中级</h3></h3><p>   此处NTU和Caltech两个大学的课程是由《Learning from Data》一书的两个不同的作者讲的，所以仅仅只需选择一个完成即可，注意：如果选择完成NTU的机器学习课程，则<strong>NTU的“机器学习基石”和“机器学习技法”需同时完成。</strong>。</p>
<table>
<thead>
<tr>
<th style="text-align:left">课程</th>
<th style="text-align:center">机构</th>
<th style="text-align:center">参考书</th>
<th style="text-align:center">Notes等其他资料</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="https://www.coursera.org/instructor/htlin" target="_blank" rel="external">机器学习基石</a></td>
<td style="text-align:center">NTU</td>
<td style="text-align:center"><a href="https://www.amazon.com/gp/product/1600490069" target="_blank" rel="external">Learning from Data</a></td>
<td style="text-align:center"><a href="https://www.csie.ntu.edu.tw/~htlin/course/mlfound16fall/" target="_blank" rel="external">链接</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="https://www.coursera.org/instructor/htlin" target="_blank" rel="external">机器学习技法</a></td>
<td style="text-align:center">NTU</td>
<td style="text-align:center">暂无</td>
<td style="text-align:center"><a href="https://www.csie.ntu.edu.tw/~htlin/course/ml15fall/" target="_blank" rel="external">链接</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="http://open.163.com/movie/2008/1/M/C/M6SGF6VB4_M6SGHFBMC.html" target="_blank" rel="external">机器学习</a></td>
<td style="text-align:center">Stanford</td>
<td style="text-align:center">暂无</td>
<td style="text-align:center"><a href="http://cs229.stanford.edu/materials.html" target="_blank" rel="external">链接</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="https://www.youtube.com/watch?v=mbyG85GZ0PI&amp;index=1&amp;list=PLD63A284B7615313A" target="_blank" rel="external">机器学习</a></td>
<td style="text-align:center">Caltech</td>
<td style="text-align:center"><a href="https://www.amazon.com/gp/product/1600490069" target="_blank" rel="external">Learning from Data</a></td>
<td style="text-align:center"><a href="http://work.caltech.edu/lectures.html" target="_blank" rel="external">链接</a></td>
</tr>
</tbody>
</table>
<h2 id="推荐书籍列表"><a href="#推荐书籍列表" class="headerlink" title="推荐书籍列表"></a><h2 id="booklists">推荐书籍列表</h2></h2><p>   以下推荐的书籍都是公认的机器学习领域界的好书，建议<strong>一般难度的书籍至少详细阅读一本，建议看两本</strong>，而较难的书籍不做任何要求，大家可以在学有余力时细细品味经典。</p>
<table>
<thead>
<tr>
<th style="text-align:left">书名</th>
<th style="text-align:center">难度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="https://www.amazon.cn/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E6%9D%8E%E8%88%AA/dp/B007TSFMTA" target="_blank" rel="external">统计学习方法</a></td>
<td style="text-align:center">一般</td>
</tr>
<tr>
<td style="text-align:left"> <a href="http://www-bcf.usc.edu/~gareth/ISL/" target="_blank" rel="external">An Introduction to Statistical Learning</a></td>
<td style="text-align:center">一般</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://www.amazon.com/gp/product/0071154671?ie=UTF8&amp;tag=jefork-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0071154671" target="_blank" rel="external">Machine Learning</a></td>
<td style="text-align:center">一般</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://www.amazon.com/gp/product/1600490069" target="_blank" rel="external">Learning from Data</a></td>
<td style="text-align:center">一般，<a href="https://work.caltech.edu/telecourse.html" target="_blank" rel="external">配套讲义</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="https://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738/ref=pd_sim_14_1?ie=UTF8&amp;dpID=61f0EXfMRvL&amp;dpSrc=sims&amp;preST=_AC_UL160_SR118%2C160_&amp;refRID=119X50P5F0DFA339S9DR" target="_blank" rel="external">Pattern Recognition and Machine Learning</a></td>
<td style="text-align:center">较难(偏贝叶斯),<a href="http://cs.brown.edu/courses/csci1420/lectures.html" target="_blank" rel="external">配套讲义</a></td>
</tr>
<tr>
<td style="text-align:left"><a href="https://www.amazon.com/The-Elements-Statistical-Learning-Prediction/dp/0387848576/ref=pd_sim_14_2?ie=UTF8&amp;dpID=41LeU3HcBdL&amp;dpSrc=sims&amp;preST=_AC_UL160_SR103%2C160_&amp;refRID=119X50P5F0DFA339S9DR" target="_blank" rel="external">The Elements of Statistical Learning</a></td>
<td style="text-align:center">较难</td>
</tr>
<tr>
<td style="text-align:left"><a href="http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf" target="_blank" rel="external">Understanding Machine Learning:From Theory to Algorithms</a></td>
<td style="text-align:center">较难</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020" target="_blank" rel="external">Machine Learning: A probabilistic approach</a></td>
<td style="text-align:center">较难</td>
</tr>
</tbody>
</table>
<h2 id="机器学习专项领域学习"><a href="#机器学习专项领域学习" class="headerlink" title="机器学习专项领域学习"></a><h3 id="special_learning">机器学习专项领域学习</h3></h2><p>如果您已经完成了上述的所有科目，恭喜您已经拥有十分扎实的机器学习基础了，已经是一名合格的机器学习成员了，可以较为顺利的进入下面某一专项领域进行较为深入研究,因为并不是所有的专项领域都有对应的课程或者书籍等学习资料，所以此处我们仅列举一些我们知道的专项领域的学习资料，当然这些领域不能涵盖所有，还有很多领域没有整理（希望大家一起完善），如果这些领域适合你，那就继续加油！如果不清楚，那么大家可以去下面列举的高级会议期刊上去寻找自己感兴趣的话题进行学习研究。</p>
<h3 id="一些专项领域资料"><a href="#一些专项领域资料" class="headerlink" title="一些专项领域资料"></a><h3 id="special_learning_data">一些专项领域资料</h3></h3><ul>
<li><a href="https://github.com/JustFollowUs/Deep-Learning" target="_blank" rel="external">深度学习</a></li>
<li><a href="https://github.com/JustFollowUs/Probabilistic-graphical-models" target="_blank" rel="external">图模型</a></li>
<li><a href="https://github.com/JustFollowUs/Reinforcement-Learning" target="_blank" rel="external">强化学习</a></li>
<li><a href="http://cs.nju.edu.cn/lwj/L2H.html" target="_blank" rel="external">Hash</a> </li>
<li><a href="https://github.com/JustFollowUs/Theoretical-Machine-Learning/" target="_blank" rel="external">理论机器学习</a></li>
<li>其他(尚未完善)</li>
</ul>
<h3 id="领域会议期刊"><a href="#领域会议期刊" class="headerlink" title="领域会议期刊"></a><h3 id="special_learning_data">领域会议期刊</h3></h3><ul>
<li><a href="https://nips.cc/" target="_blank" rel="external">NIPS</a></li>
<li><a href="http://icml.cc/" target="_blank" rel="external">ICML</a></li>
<li><a href="http://www.aaai.org/" target="_blank" rel="external">AAAI</a></li>
<li><a href="http://www.ijcai.org/" target="_blank" rel="external">IJCAI</a></li>
<li><a href="http://www.kdd.org/" target="_blank" rel="external">KDD</a></li>
<li><a href="http://www.cs.uvm.edu/~icdm/" target="_blank" rel="external">ICDM</a></li>
<li><a href="http://www.learningtheory.org/" target="_blank" rel="external">COLT</a></li>
<li>其他(尚未完善)</li>
</ul>
<h2 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a><h2 id="many_thanks">致谢</h2></h2><p>  感谢南京大学LAMDA实验组杨杨博士的建议与资料的分享。</p>
<p>原文链接：<a href="https://github.com/JustFollowUs/Machine-Learning" target="_blank" rel="external">https://github.com/JustFollowUs/Machine-Learning</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/08/16/Snowboy使用说明_Hotword Detection/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Andy Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Andy's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/16/Snowboy使用说明_Hotword Detection/" itemprop="url">Snowboy使用说明_Hotword Detection</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-16T00:00:00+08:00">
                2017-08-16
              </time>
            

            

            
          </span>

		  
		  
          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/树莓派3/" itemprop="url" rel="index">
                    <span itemprop="name">树莓派3</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
			
			
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Snowboy是一个高度自定义的基于实时甚至离线情况的hotword detection engine(敏感词检测机制？)，兼容Raspberry Pi,Linux and Mac OS X.</p>
<p>hotword也被称为唤醒词(wake word)或触发词(trigger word)通常是一个关键词或短语，计算机会一直监听作为一个信号用于触发其他操作。</p>
<p>有一些例子，如Amazon Echo的“Alexa”、Google Assistant的”OK Google”和iPhone的“Hey Siri”. 这些关键词用于触发一个全面的语音交互。但是，hotwords同样可以用于其他方面，像是命令和控制等。</p>
<p>一种简单的方案是，运行全ASR(Automatic Speech Recognition)来检测hotword detection.在这种方案中，设备会一直观察特定触发词。但是ASR也会消耗设备和带宽资源。同样的，如果基于云的应用，将不能保护你的隐私。（因为会一直开着麦克风来检测关键词，那么周围环境包括你说的话也会实时被监听了).幸运的是，Snowboy会用来解决此类问题。</p>
<ul>
<li>highly customizable(高度自定义）</li>
<li>always listening but protects your privacy(总是检测但是不会泄露隐私）</li>
<li>light-weight and embedded</li>
<li>Apache licensed!</li>
</ul>
<p><img src="http://i.imgur.com/iJulCvp.jpg" alt="Snowboy"></p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><p>准备工作：</p>
<ol>
<li>一台带有microphone的设备</li>
<li>相应的解压软件 </li>
<li>训练好的模型</li>
</ol>
<p><a href="https://s3-us-west-2.amazonaws.com/snowboy/snowboy-releases/rpi-arm-raspbian-8.0-1.1.1.tar.bz2" target="_blank" rel="external">树莓派pre-packaged</a></p>
<h3 id="Access-Microphone"><a href="#Access-Microphone" class="headerlink" title="Access Microphone"></a>Access Microphone</h3><p>使用PortAudio作为一个跨平台的音频输入/输出。同样也使用sox快速检查microphone是否正确安装。</p>
<ol>
<li>Install Sox</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install python-pyaudio python3-pyaudio sox</div></pre></td></tr></table></figure>
<ol>
<li>Install PortAudio’s Python bindings:</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">pip install pyaudio</div><div class="line"><span class="comment">#pip-3.2 install pyaudio</span></div></pre></td></tr></table></figure>
<ol>
<li>To check whether you can record via your microphone, open a terminal and run:</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">rec temp.wav</div><div class="line"><span class="comment">#记录个几秒中，ctrl+c,再play temp.wav,听声</span></div></pre></td></tr></table></figure>
<h3 id="Decoder-Structures"><a href="#Decoder-Structures" class="headerlink" title="Decoder Structures"></a>Decoder Structures</h3><p>上面预安装包下载解压后，如下：</p>
<blockquote>
<p>├── README.md</p>
<p>├── _snowboydetect.so</p>
<p>├── demo.py</p>
<p>├── demo2.py</p>
<p>├── light.py</p>
<p>├── requirements.txt</p>
<p>├── resources</p>
<p>│   ├── ding.wav</p>
<p>│   ├── dong.wav</p>
<p>│   ├── common.res</p>
<p>│   └── snowboy.umdl</p>
<p>├── snowboydecoder.py</p>
<p>├── snowboydetect.py</p>
<p>└── version</p>
</blockquote>
<p><strong>_snowboydetect.so</strong>是用SWIG编译的一个动态链接库，依赖于系统的Python2库。snowboy所有相关库都被静态连接在这个文件里。</p>
<p><strong>snowboydetect.py</strong>是一个SWIG生成的python wrapper文件。因为不易阅读，我们创建了高等级的wrapper: <strong>snowboydecoder.py</strong></p>
<p>应该在<a href="https://snowboy.kitt.ai" target="_blank" rel="external">https://snowboy.kitt.ai </a>上训练你的模型(snowboy.pmdl)，或者你也可以使用同一模型<strong>resources/snowboy.umdl</strong></p>
<h3 id="Runing-a-Demo"><a href="#Runing-a-Demo" class="headerlink" title="Runing a Demo"></a>Runing a Demo</h3><ol>
<li>To access the simple demo in <strong>main</strong> code of snowboydecoder.py, run the following command in your Terminal:</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">python demo.py snowboy.pmdl</div><div class="line"><span class="comment">#snowboy.pmdl是你训练的hotword模型</span></div></pre></td></tr></table></figure>
<ol>
<li>When prompt,speak into your microphone to see whether snowboy detects your magic phrase.</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="comment">#demo.py</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> snowboydecoder</div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> signal</div><div class="line"></div><div class="line">interrupted = <span class="keyword">False</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">signal_handler</span><span class="params">(signal, frame)</span>:</span></div><div class="line">   	<span class="keyword">global</span> interrupted</div><div class="line">   	interrupted = <span class="keyword">True</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">interrupt_callback</span><span class="params">()</span>:</span></div><div class="line">    <span class="keyword">global</span> interrupted</div><div class="line">    <span class="keyword">return</span> interrupted</div><div class="line"></div><div class="line"><span class="keyword">if</span> len(sys.argv) == <span class="number">1</span>:</div><div class="line">    print(<span class="string">"Error: need to specify model name"</span>)</div><div class="line">    print(<span class="string">"Usage: python demo.py your.model"</span>)</div><div class="line">    sys.exit(<span class="number">-1</span>)</div><div class="line"></div><div class="line">model = sys.argv[<span class="number">1</span>]</div><div class="line"></div><div class="line">signal.signal(signal.SIGINT, signal_handler)</div><div class="line"></div><div class="line">detector = snowboydecoder.HotwordDetector(model, sensitivity=<span class="number">0.5</span>)</div><div class="line">print(<span class="string">'Listening... Press Ctrl+C to exit'</span>)</div><div class="line"></div><div class="line">detector.start(detected_callback=snowboydecoder.ding_callback,</div><div class="line">               interrupt_check=interrupt_callback,</div><div class="line">               sleep_time=<span class="number">0.03</span>)</div><div class="line"></div><div class="line">detector.terminate()</div></pre></td></tr></table></figure>
<p>主程序在<strong>detector.start()</strong>中循环，每<strong>sleep_time=0.03</strong>:</p>
<ol>
<li>检查ring buffer 是否有hotword, if <strong>YES</strong>,调用<strong>detected_callback</strong>函数</li>
<li>调用<strong>interrupt_check</strong>函数，if <strong>True</strong>，中断主程序，返回.</li>
</ol>
<p>目前，在demo中令detected_callback=snowboydecoder.ding_callback,所以每当检测到关键词时，设备会“叮”一下。</p>
<p><strong>原文出处</strong>：<a href="http://docs.kitt.ai/snowboy/#running-a-demo" target="_blank" rel="external">http://docs.kitt.ai/snowboy/#running-a-demo</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/08/11/ReSpeaker智能语音双麦克风阵列/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Andy Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Andy's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/11/ReSpeaker智能语音双麦克风阵列/" itemprop="url">ReSpeaker智能语音双麦克风阵列</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-11T00:00:00+08:00">
                2017-08-11
              </time>
            

            

            
          </span>

		  
		  
          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/树莓派3/" itemprop="url" rel="index">
                    <span itemprop="name">树莓派3</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
			
			
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>去年圣诞节买了块树莓派，看了网上好多基于树莓派的DIY语音助手，一直想自己也山寨一个。主要有两个问题，一是语音输入如何解决？二是Alexa和google home都是国外，不仅仅是不支持中文，而且还有一堵“墙”在，比较麻烦。</p>
<p>第一个问题，网上主要有两种办法，要么直接搞免驱mini USB麦克风或者大的比较丑的的麦克风，要么就是科技范十足的麦克风阵列。我是非常倾向于用麦克风阵列的，也没想4麦克、7麦克、8麦克等，两麦克阵列就OK了，但是找了一圈没找着合适的。主要是价钱太贵，不忍心剁手。后来将就着买了个mini USB麦克风，但是除了敲桌子声音或者直接吼，根本没啥效果，检测不到声音(明明看着国外的小哥哥们用的挺好的。。。也可能是淘宝上买到假货了)。</p>
<p><img src="https://ksr-ugc.imgix.net/assets/013/450/587/88ed9594144b9cf686c055b282e3fa4b_original.jpg?w=680&amp;fit=max&amp;v=1471845738&amp;auto=format&amp;q=92&amp;s=3e81cd923a00655c28c20c5b143b57c2" alt="麦克风阵列"></p>
<p><img src="https://gd4.alicdn.com/imgextra/i2/329675712/TB2FS30spXXXXX6XpXXXXXXXXXX_!!329675712.jpg_400x400.jpg" alt="mini USB麦克风"></p>
<p>第二个，明显今年百度开始在AI上下了不少功夫。语音这一块，主要有UNIT、DuerOS平台。虽然做的没有Google Home 和Alexa那么知名，但是支持中文，而且在国内。</p>
<p>所以借着百度之星UNIT对话系统，又开始了我的瞎折腾(之前搞了Alexa和Google Home,加上不支持中文、墙、硬件问题等，搞得头大就放弃了)。这一次，借助着百度AI平台，语音识别转文字，然后利用UNIT解析，再语音合成输出。那么就剩下硬件了，还是上面的选择，USB麦克风或者麦克风阵列。经人推荐，找到了一款双麦克阵列模块，兼容树莓派3，淘宝上有旗舰店，80元RMB.(哈哈，当时直接就下单了！)</p>
<p>淘宝上给的简介是：</p>
<blockquote>
<h3 id="ReSpeaker智能语音方案-双麦克风扩展板-兼容树莓派Zero-3B-2B"><a href="#ReSpeaker智能语音方案-双麦克风扩展板-兼容树莓派Zero-3B-2B" class="headerlink" title="ReSpeaker智能语音方案 双麦克风扩展板 兼容树莓派Zero/3B/2B"></a>ReSpeaker智能语音方案 双麦克风扩展板 兼容树莓派Zero/3B/2B</h3><p>此产品集成了亚马逊语言和谷歌助手等，兼容树莓派Zero、树莓派3B/2B，可以构建一个更强大更灵活的语音产品。</p>
</blockquote>
<p><a href="https://item.taobao.com/item.htm?spm=a1z10.3-c.w4002-11172317909.38.5e478797SzWPpR&amp;id=553438198956" target="_blank" rel="external">淘宝链接</a></p>
<p>但实际上，这货的外国名是<strong>ReSpeaker 2-Mics Pi HAT</strong></p>
<p><a href="http://wiki.seeed.cc/Respeaker_2_Mics_Pi_HAT/" target="_blank" rel="external">相关链接</a></p>
<p><img src="https://github.com/SeeedDocument/MIC_HATv1.0_for_raspberrypi/blob/master/img/2mics-zero-high-res.jpg?raw=true" alt="ReSpeaker 2-Mics Pi HAT"></p>
<p>ReSpeaker 2-Mics Pi HAT是一款为树莓派而设计针对AI或语音应用的双麦克风扩展板。这意味着你可以基于树莓派（集成Amazon Alexa,Google Assistant)建立一个更强大、更灵活的语音产品.</p>
<p>这块板子基于WM8960,一片低功耗立体声编解码器。有两个麦克风分别位于板子的两侧用于采集声音。板子上还有3个APA102 RGB LED,1个用户按键和两个Grove接口用于扩展应用。更惊喜的是，还有3.5mm Audio Jack和JST 2.0 Speaker接口用于输出声音。</p>
<h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><ul>
<li>兼容树莓派(Raspberry Pi Zero and Zero W, Raspberry Pi B+,Raspberry Pi 2B and Raspberry Pi 3B)</li>
<li>2个麦克风</li>
<li>2个Grove接口</li>
<li>1个用户按键</li>
<li>3.5mm音频接口</li>
<li>JST2.0音频输出</li>
</ul>
<h2 id="应用领域"><a href="#应用领域" class="headerlink" title="应用领域"></a>应用领域</h2><ul>
<li>语音交互应用</li>
<li>AI助手</li>
</ul>
<h2 id="硬件介绍"><a href="#硬件介绍" class="headerlink" title="硬件介绍"></a>硬件介绍</h2><p><img src="https://github.com/SeeedDocument/MIC_HATv1.0_for_raspberrypi/blob/master/img/mic_hatv1.0.png?raw=true" alt="Hardware Overview"></p>
<ul>
<li>BUTTON:用户按键，连接到GPIO17</li>
<li>MIC_L &amp; MIC_R:位于板子两侧的麦克风</li>
<li>RGB LED:3颗APA102 RGB LED,连接到了SPI接口</li>
<li>WM8960: 低功耗立体声编解码器</li>
<li>Raspberry Pi 40-Pin Headers:</li>
<li>POWER:板子的USB供电口，当使用扬声器时，要保证足够的电流</li>
<li>I2C:Grove I2C接口，连接I2C-1</li>
<li>GPIO 12：Grove 数字端口，连接GPIO12 &amp; GPIO13</li>
<li>JST 2.0 SPEAKER OUT:连接扬声器</li>
<li>3.5mm AUDIO JACK:连接带有3.5mm插口的耳机或扬声器</li>
</ul>
<p>具体配置及使用参考：<a href="http://wiki.seeed.cc/Respeaker_2_Mics_Pi_HAT/" target="_blank" rel="external">http://wiki.seeed.cc/Respeaker_2_Mics_Pi_HAT/</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/08/10/百度之星开发者大赛-资格赛2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Andy Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Andy's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/10/百度之星开发者大赛-资格赛2/" itemprop="url">2017百度之星开发者大赛--资格赛2</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-10T00:00:00+08:00">
                2017-08-10
              </time>
            

            

            
          </span>

		  
		  
          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/UNIT/" itemprop="url" rel="index">
                    <span itemprop="name">UNIT</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
			
			
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>7月28日，百度之星小姐姐给打过电话后，连着搞了两天，其实也没两天，还帮老板整理了好些文档资料。前一篇博客上也说了，搞了69.06分，第9名。然后想着反正肯定可以进前100啦，就没怎么管理了。优化方案也是按着百度AI开发论坛上提供的<a href="http://developer.baidu.com/forum/topic/show?topicId=241520" target="_blank" rel="external">UNIT机器人优化指南</a>结合UNIT使用手册做的。</p>
<p>最后结果：</p>
<p><img src="http://i.imgur.com/R6cgjjZ.png" alt="第六名"></p>
<p>事先，基本的意图、词槽、Bot回应等等按照规定做好。实际中，我开始就没认真搞好，漏了一个错误的词槽。但是在最后资格赛结束之前发现了，改正之后提高了1点几个分数。</p>
<p>基本的对话系统搞定之后，后期的优化主要分为两块：</p>
<ul>
<li>增加对话样本集</li>
<li>增加对话模板集</li>
</ul>
<p>对话样本集对应着样本学习，假设对话样本足够多、样本质量非常高，那通过神经网络学习得到的模型自然也不会差。</p>
<p>对话模板集则是对应着规则学习，正常人对话时，会有一定的语言结构，如，主语+谓语+宾语结构。特别是在一个特定的场景下，可以充分考虑到用户的对话的模板，进行一些提炼，得到一些语言“公式”。显然这种对话模板集方式的泛化能力是有限的，但是它的优点在于可以保证在符合“公式”的对话时不会出现错误。</p>
<p>我所侧重的是第一个方法，即增加对话样本集。使用了目前UNIT的隐藏功能，推荐对话样本。自己可以先整一个小的对话样本，然后让UNIT平台根据自己DIY的对话样本生成一些样本，然后自己去标注。大约标注了3500个样本吧，自己整的样本比例是按照百度提供的对话样本中各个意图的比例整的，保证同分布吧。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/07/30/百度之星开发者大赛-资格赛/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Andy Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Andy's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/07/30/百度之星开发者大赛-资格赛/" itemprop="url">2017百度之星开发者大赛--资格赛</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-07-30T00:00:00+08:00">
                2017-07-30
              </time>
            

            

            
          </span>

		  
		  
          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/UNIT/" itemprop="url" rel="index">
                    <span itemprop="name">UNIT</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
			
			
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>之前有看到网上说每年百度之星是一个不错的编程比赛，可以检验一下自己的编程能力。所以，当宿舍楼下见到贴的海报的时候也就报名了，报名的时候发现今年百度之星有些变革。与以往不同的是，今年多了个百度之星开发者大赛，以前都是程序设计大赛啊（全TM是那帮搞ACM的天下啊。。。）。仔细想想前段时间搞美团的Code-M比赛，那叫一个惨啊，不是不会啊，全是运行超时，需要优化！咱们又不是计算机学院的，又不没搞过ACM,没练过啊。于是这次直接就报了开发者大赛，都没看看程序设计是搞啥的。</p>
<p><img src="http://astar2017.baidu.com/Public/img/developer-banner.jpg" alt=""></p>
<p>开发者大赛是利用百度自己一个新的平台UNIT(<strong>Understanding and Interaction Technology</strong>),之前博客也介绍过。估计百度是想借着比赛推广一下平台，顺便再收集一些数据。总之，利用UNIT平台做出一个东西，如智能硬件、APP啥的，没有具体的限制。</p>
<p>比赛分为资格赛和正赛两部分，资格赛是用来熟悉UNIT平台的，只有在两个场景下进入前200名的才有资格进入正赛。</p>
<blockquote>
<p>资格赛任务介绍</p>
<p>   任务：基于UNIT平台优化给定场景的对话能力</p>
<p>使用UNIT平台优化题设场景的对话能力，提供两个固定场景供参赛者选择：</p>
<ul>
<li>场景一：订餐馆，包括查询餐馆、订位或发起导航</li>
<li>场景二：看电影，包括查询电影、影院、购票电影票</li>
</ul>
<p>每个场景由主办方预先提供意图与词槽的定义，并提供一定量对话样本作为训练数据。参赛者需要使用<br>UNIT完成场景的意图与词槽的配置，并利用对话样本优化场景的对话理解能力（参赛者自行增加对话样本<br>与词槽的词表等），并最终在UNIT平台上产出模型与服务。</p>
<p>正赛任务介绍</p>
<p>任务：设计和开发一个以对话式人机交互为核心的智能产品</p>
<p>产品形式包括但不限于手机APP、智能硬件等。产品必须使用百度提供的理解与交互技术平台（以下简称&gt; &gt; UNIT平台）实现核心对话能力，可以使用百度AI平台开放的其他技术能力作为辅助，其余百度未提供的功&gt; 能与能力，实现形式不限。</p>
</blockquote>
<p>刚开始接触感觉挺难的，想找些队员，在群里吼了两嗓子，但只有两个妹子回应，最后也就没有了下文。正好自己又忙着开题，也就打算放弃了。就这样，7月28号，这次百度之星的组织者吧，听声音应该是个小姐姐直接打电话过来了。说是资格赛不是很难，尽量还是参与一下，比较容易可以进正赛。还举例子说东北大学、大连理工的几位同学两天就搞到了60、70分。后来，想了下，觉得也是，小姐姐都打电话过来了。抱着试一试的心态，搞了将近两天吧，69.06分，第9名。</p>
<p><img src="http://i.imgur.com/ZU0nvq6.png" alt=""></p>
<p><img src="http://i.imgur.com/Touvwb3.png" alt=""></p>
<p>头半天在及格线附近，又连忙按着使用手册搞了一天，标注了快3000条样本才把分数提上去。下回写一下具体优化过程，感觉UNIT平台以后要是集成语音交互功能，再加上百度的中文处理资源，还是有一定钱途的。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/07/27/台湾国立清华大学彭明辉研究生手册/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Andy Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Andy's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/07/27/台湾国立清华大学彭明辉研究生手册/" itemprop="url">台湾国立清华大学彭明辉研究生手册【转】</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-07-27T13:37:43+08:00">
                2017-07-27
              </time>
            

            

            
          </span>

		  
		  
          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/鸡汤/" itemprop="url" rel="index">
                    <span itemprop="name">鸡汤</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
			
			
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>#一、论文的要求  #</p>
<p>　　我对硕士论文的基本要求是：</p>
<p>　　<strong>（1）</strong>论文的主要内容，是叙述一套方法在一个特定场合中的应用。</p>
<p>　　<strong>（2）</strong>这套方法必须要有所创新或突破，并因而对学术界有所贡献。因此，它或者是解决既有问题的新方法，或者是既有方法的新应用，或者是以一个新的方法开启一整片新的应用领域。</p>
<p>　　<strong>（3）</strong>在论文中，你必须要有能力提出足够的证据来让读者信服说：针对这个应用场合，你所提出来的方法确实有比文献中一切既有方法更优越之处。</p>
<p>　　<strong>（4）</strong>此外，你必须要能清楚指出这个方法在应用上的限制，并且提出充分证据来说服读者：任何应用场合，只要能够满足你所提出来的假设（前提）条件，你的方法就一定适用，而且你所描述的优点就一定会存在。</p>
<p>　　<strong>（5）</strong>你还必须要在论文中清楚指出这个方法的限制和可能的缺点（相对于其它文献上的既有方法，或者在其它应用场合里）。假如这个方法有任何重大缺点，在口试时才被口试委员指出来，其后果有可能是论文无法通过。</p>
<p>　　<strong>（6）</strong>行文风格上，它是一篇论证严谨，逻辑关系清晰，而且结构有条理的专业论述。也就是说，在叙述你的方法的过程，你必须要清清楚楚地交代这个方法的应用程序以及所有仿真或实验结果的过程，使得这个专业领域内的任何读者，都有办法根据你的描述，在他的实验室下复制出你的研究成果，以便确定你的结论确实是可以「在任何时间、任何地点、任何人」都具有可重复性（可重复性是「科学」的根本要求）。</p>
<p>　　<strong>（7）</strong>而且，你对这个方法的每一个步骤都必须要提供充分的理由说明「为什么非如此不可」。</p>
<p>　　<strong>（8）</strong>最后，你的论文必须要在适当位置清楚注明所有和你所研究之题目相关的文献。而且，你必须要记得：只要是和你所研究的问题相关的学术文献（尤其是学术期刊论文），你都有必要全部找出来（如果漏掉就是你的过失），仔细读过。假如你在学位论文口试时，有口试委员指出有一篇既有文献，在你所讨论的问题中处理得比你的方法还好，这就构成你论文无法及格的充分理由。</p>
<p>　　<strong>（9）</strong>第（2）款所谓「对学术界的贡献」，指的是：把你的所有研究成果扣除掉学术界已经发表过的所有成果（不管你实际上有没有参考过，没有参考过也算是你的重大过失），剩下的就是你的贡献。假如这个贡献太少，也构成你论文无法及格的充分理由。</p>
<p>　　上面所叙述的九款要件中，除第（2）款之外，通通都是必须要做到的，因此没有好坏之分。一篇硕士论文的好坏（以及成绩的评定标准），主要是看第（2）款所谓「对学术界的贡献」的多寡与重要性而定。假如你要申请国外的博士班，最重要的也是看你的硕士论文有什么「贡献」而定（这往往比TOFEL、GRE、GPA还重要）。</p>
<p>　　一个判断硕士论文的好坏有一个粗浅办法：假如你的研究成果可以在国外著名学术期刊（journals，而非 magazines）上发表，通常就比一篇只能在国外学术会议（conferences）上发表的硕士论文贡献多；一篇国外学术会议的论文又通常比无法发表的论文贡献多；在国际顶尖学术期刊上发表的论文通常比一篇二流的学术期刊论文贡献多。SCI有一种叫做 Impact Factor 的指数，统计一个期刊每篇论文被引述的次数。通常这个次数（或指数）愈高，对学术界的影响力就愈大。以机械视觉相关领域的期刊而言，Impact Factor 在 1.0 以上的期刊，都算是顶尖的期刊。这些期刊论文的作者，通常是国外顶尖学府的著名教授指导全球一流的博士生做出来的研究成果。</p>
<h1 id="二、完成硕士论文所需要的能力"><a href="#二、完成硕士论文所需要的能力" class="headerlink" title="二、完成硕士论文所需要的能力"></a>二、完成硕士论文所需要的能力</h1><p>　　从前面的叙述可以归纳出来，完成硕士论文所需要的能力包括以下数项，依它们的培养先后次序逐项讨论。</p>
<p>　　<strong>（1）资料检索的能力</strong>：在给定（或自己拟定）的题目范围内，你必须有能力利用文资料索引系统，查出所有相关的论文，而无任何遗漏（否则你可能在论文口试时才发现同一个题目已经有人发表过了）。你到底要用什么样的关键词和查所程序去保证你已经找出所有相关的文献？这是第一个大的挑战。每一组关键词（包含联集与交集）代表一个论文所构成的集合，假如你用的关键词不恰当，你可能找到的集合太小，没有涵盖所有的相关文献；假如你用的关键词太一般化（譬如「image」），通常你找到的集合会太大，除了所有相关文献之外还加上好几十倍的毫不相关的文献。</p>
<p>　　<strong>（2）资料筛选的能力</strong>：即使你使用了恰当的搜寻策略，通常找到的文献集合都还是明显地比你所需要的集合大，而且通常文献比数大概在一两百篇或数百篇之间，而其中会和你的的研究子题直接且密切相关的论文，通常只有廿、卅篇左右。你如何可以只读论文的题目、摘要、简介和结论，而还没有完全看懂内文，就准确地判断出这篇论文中是否有值得你进一步参考的内容，以便快速地把需要仔细读完的论文从数百篇降低到廿、卅篇？这考验着你从事资料筛选的能力。</p>
<p>　　<strong>（3）期刊论文的阅读能力</strong>：期刊论文和大学部的课本截然不同。大学部的课本是寻次渐进地从最基本的知识背景逐步交代出整套有系统的知识，中间没有任何的跳跃，只要你逐页读下去，就可以整本都读懂，不需要在去别的地方找参考资料。但是期刊论文是没头没尾的十几页文献，只交代最核心的创意，并援引许多其它论文的研究成果（但只注明文献出处，而完全没有交代其内容）。因此，要读懂一篇论文，一定要同时读懂数篇或十数篇被援引的其它论文。偏偏，这十几篇被援引的论文又各自援引十数篇其它论文。因此，相对于大学部的教科书而言，期刊论文是一个极端没有系统的知识，必须要靠读者自己从几十篇论文中撷取出相关的片段，自己组织成一个有系统的知识，然后才有办法开始阅读与吸收。要培养出这种自己组织知识的能力，需要在学校靠着大量而持续的时间去摸索、体会，而不可能只利用业余的零星时间去培养。因此，一个大学毕业后就不再念研究所的学生，不管他在毕业生和大学毕业生最大的差别，就是：学士只学习过吸收系统知识的能力（也就是读别人整理、组织好的知识，典型的就是课本）；但硕士则学习过自己从无组织的知识中检索、筛选、组织知识的能力。</p>
<p>　　<strong>（4）期刊论文的分析能力</strong>：为了确定你的学位论文研究成果确实比所有相关的学术期刊论文都更适合处理你所拟定的应用场域，首先你必须要有能力逐篇分析出所有相关期刊论文的优点与缺点，以及自己的研究成果的优点与缺点，然后再拿他们来做比较，总结出你的论文的优点和缺点（限制）。但是，好的期刊论文往往是国外著名学府的名师和一流的博士生共同的研究成果，假如你要在锁定的应用场域上「打败」他们，突出自己的优点，这基本上是一个极端困难的挑战。即使只是要找出他们的缺点，都已经是一个相当困难的工作了。一个大学毕业生，四年下来都是假定「课本是对的」这样地学下来的，从来没有学习如何分析课本知识的优缺点，也就是「只有理解的能力，而没有批判的能力」。硕士生则必须要有「对一切既有进行精确批判」的能力。但是，这个批判并非个人好恶或情绪化的批判，而是真的找得到充分理由去支持的批判。这个批判的能力，让你有能力自己找到自己的优、缺点，因此也有机会自己精益求精。所以，一个大学毕业生在业界做事的时候，需要有人指导他（从事批判性检验），帮他找出缺点和建议改进的可能性。但是，一个严格训练过的合格硕士，他做事的时候应该是不需要有人在背后替他做检证，他自己就应该要有能力分析自己的优、缺点，主动向上级或平行单位要求支持。其实，至少要能够完成这个能力，才勉强可以说你是有「独立自主的判断能力」。</p>
<p>　　<strong>（5）创新的能力</strong>：许多大学毕业的工程师也能创新，但是硕士的创新是和全世界同一个学术团体内所有的名师和博士生挑战。因此，两者是站在不同的比较基础上在进行的：前者往往是一个企业内部的「闭门造车」，后者是一个全球的开放性竞争。其次，工程师的创新往往是无法加以明确证明其适用条件，但是学术的创新却必须要能够在创新的同时厘清这个创新的有效条件。因此，大学毕业生的主要能力是吸收既有知识，但硕士毕业生却应该要有能力创造知识。此外，台湾历年来工业产品的价位偏低，这一部分是因为国际大厂的打压以及国际消费者的信任不易建立。但是，另一方面，这是因为台湾的产品在品质上无法控制，因此只好被当作最粗糙的商品来贩卖。台湾的产品之所以无法有稳定的品质，背后的技术原因就是：各种创新都是只凭一时偶然的巧思，却没有办法进一步有系统地厘清这些巧思背后可以成立的条件。但是，创新其实是可以有一套「有迹可寻」的程序的，这是我最得意的心得，也是我最想教的。</p>
<h1 id="三、为什么要坚持培养阅读与分析期刊论文的能力"><a href="#三、为什么要坚持培养阅读与分析期刊论文的能力" class="headerlink" title="三、为什么要坚持培养阅读与分析期刊论文的能力"></a>三、为什么要坚持培养阅读与分析期刊论文的能力</h1><p>　　我所以一直坚持要训练研究生阅读与分析期刊论文的能力，主要是为了学生毕业后中长期的竞争力着想。</p>
<p>　　台湾从来都只生产国外已经有的产品，而不事创新。假如国外企业界比国外学术的技术落后三年，而台湾的技术比国外技术落后五年，则台湾业界所需要的所有技术都可以在国外学术期刊上找到主要的理论依据和技术核心构想（除了一些技术的细节和 know how 之外）。因此，阅读期刊的能力是台湾想要保持领先大陆技术的必备条件。</p>
<p>　　此外，只要能够充分掌握阅读与分析期刊论文的技巧，就可以水到渠成地轻松进行「创新」的工作。所以，只要深入掌握到阅读与分析期刊论文的技巧，就可以掌握到大学生不曾研习过的三种能力：（1）自己从无组织的知识中检索、筛选、组织知识的能力、（2）对一切既有进行精确批判的独立自主判断能力、（3）创造新知识的能力。</p>
<p>　　创新的能力在台湾一直很少被需要（因为台湾只会从国外买整套设备、制程和设计与制造的技术）。但是，大陆已经成为全球廉价品制造中心，而台商为了降低成本也主动带技术到大陆设厂（包括现在的晶元代工），因此整个不具关键性技术的制造业都会持续往大陆移动；甚至 IC 的设计（尤其数字的部分）也无可避免地会迅速朝向「台湾开系统规格，进行系统整合，大陆在前述架构下开发特定数位模块」的设计代工发展。因此，未来台湾将必然会被逼着朝愈来愈创意密集的创意中心走（包括商务创意、经营创意、产品创意、与技术创新）。因此，不能因为今天台湾的业界不需要创新的能力，就误以为自己一辈子都不需要拥有创新的能力。</p>
<p>　　我在协助民间企业发展技术研发的过程中，碰到过一位三十多岁的厂长。他很聪明，但从小家穷，被环境逼着去念高工，然后上夜校读完工专。和动态性能（ bandwidth、response speed等）无关的技术他都很深入，也因为产品升级的需要而认真向我求教有关动态性能的基本观念。但是，怎么教他都不懂，就只因为他不懂工程数学。偏偏，工程数学不是可以在工厂里靠自修读会的。一个那么聪明的人，只因为不懂工数，就注定从三十岁以后一辈子无法在专业上继续成长！他高工毕业后没几年，廿多岁就当课长，家人与师长都以他为荣；卅岁当厂长，公司还给他技术股，前途无量；谁想得到他会在卅岁以后被逼着「或者升级，或者去大陆，或者失业」？</p>
<p>　　每次想起这位厂长，看着迫不急待地要到台积电去「七年赚两千万退休金」的学生，或者只想学现成可用的技术而不想学研究方法的学生，我总忍禁不住地要想：十年后，我教过的学生里，会不会有一堆人就只因为不会读期刊论文而被逼提前退休？</p>
<p>　　再者，技术的创新并不是全靠聪明。我熟谙一套技术创新的方法，只要学会分析期刊论文的优缺点，就可拿这套方法分析竞争对手产品的优缺点；而且，只要再稍微加工，就可以从这套优缺点的清单里找到突破瓶颈所需的关键性创意。这套创新程序，可以把「创新」变成不需要太多天分便可以完成的事，从而减轻创意的不定性与风险性。因此，只要会分析论文，几乎就可以轻易地组合出你所需要的绝大部分创意。聪明是不可能教的，但这套技巧却是可以教的；而且只要用心，绝大部分硕士生都可以学会。</p>
<p>　　就是因为这个原因，我的实验室整个训练的重心只有一个：通过每周一次的 group meeting，培养学生深入掌握阅读与分析期刊论文的技巧，进而培养他们在关键问题上突破与创新的能力。</p>
<h1 id="四、期刊论文的分析技巧与程序"><a href="#四、期刊论文的分析技巧与程序" class="headerlink" title="四、期刊论文的分析技巧与程序"></a>四、期刊论文的分析技巧与程序</h1><p>　　一般来讲，好的期刊论文有较多的创意。虽然读起来较累，但收获较多而深入，因此比较值得花心思去分析。读论文之前，参考SCI Impact Factor 及学长的意见是必要的。</p>
<p>　　一篇期刊论文，主要分成四个部分。</p>
<p>　　<strong>（1）Abstract：</strong></p>
<p>　　说明这篇论文的主要贡献、方法特色与主要内容。最慢硕二上学期必须要学会只看 Abstract 和Introduction便可以判断出这篇论文的重点和你的研究有没有直接关连，从而决定要不要把它给读完。假如你有能力每三十篇论文只根据摘要和简介便能筛选出其中最密切相关的五篇论文，你就比别人的效率高五倍以上。以后不管是做事或做学术研究，都比别人有能力从更广泛的文献中挑出最值得参考的资料。</p>
<p>　　<strong>（2）Introduction：</strong></p>
<p>　　Introduction 的功能是介绍问题的背景和起源，交代前人在这个题目上已经有过的主要贡献，说清楚前人留下来的未解问题，以及在这个背景下这篇论文的想解决的问题和它的重要性。对初学的学生而言，从这里可以了解以前研究的概况。通常我会建议初学的学生，对你的题目不熟时，先把跟你题目可能相关的论文收集个 30～40篇，每篇都只读Abstract 和 Introduction，而不要读 Main Body（本文），只在必要时稍微参考一下后面的 Illustrative examples和 Conclusions，直到你能回答下面这三个问题：（2A）在这领域内最常被引述的方法有哪些？（2B）这些方法可以分成哪些主要派别？（2C）每个派别的主要特色（含优点和缺点）是什么？</p>
<p>　　问题是，你怎么去找到这最初的30～40篇论文？有一种期刊论文叫做「review paper」，专门在一个题目下面整理出所有相关的论文，并且做简单的回顾。你可以在搜寻 Compendex 时在 keywords 中加一个「review」而筛选出这类论文。然后从相关的数篇review paper 开始，从中根据 title 与 Abstract 找出你认为跟你研究题目较相关的30～40篇论文。</p>
<p>　　通常只要你反复读过该领域内30～40篇论文的Abstract 和 Introduction，你就应该可以从Introduction的评论中回答（2A）和（2B）这两个问题。尤其要记得，当你阅读的目的是要回答（2A）和（2B）这两个问题时，你一定要先挑那些 Introduction写得比较有观念的论文念（很多论文的Introduction 写得像流水帐，没有观念，这种论文刚开始时不要去读它）。假如你读过假如30～40篇论文的 Abstract 和 Introduction之后，还是回答不了（2C），先做下述的工作。</p>
<p>　　你先根据（2A）的答案，把这领域内最常被引述的论文找齐，再把他们根据（2B）的答案分成派别，每个派别按日期先后次序排好。然后，你每次只重新读一派的 Abstract 和 Introduction（必要时简略参考内文，但目的只是读懂Introduction内与这派有关的陈述，而不需要真的看懂所有内文），照日期先后读 ，读的时候只企图回答一个问题：这一派的创意与主要诉求是什么？这样，你逐派逐派地把每一派的Abstract 和 Introduction 给读完，总结出这一派主要的诉求 、方法特色和优点（每一篇论文都会说出自己的优点，仔细读就不会漏掉）。</p>
<p>　　其次，你再把这些论文拿出来，但是只读Introduction，认真回答下述问题：「每篇论文对其它派别有什么批评？」然后你把读到的重点逐一记录到各派别的「缺点」栏内。</p>
<p>　　通过以上程序，你就应该可以掌握到（2A）、（2B）、和（2C）三个问题的答案。这时你对该领域内主要方法、文献之间的关系算是相当熟捻了，但是你还是只仔细 读完Abstract 和 Introduction而已，内文则只是笼统读过。</p>
<p>　　这时候，你已经掌握到这领域主要的论文，你可以用这些论文测试看看你用来搜寻这领域论文的 keywords 到底恰不恰当，并且用修正过的 keywords 再搜寻一次论文，把这领域的主要文献补齐，也把原来30～40篇论文中后来发现关系较远的论文给筛选掉，只保留大概20篇左右确定跟你关系较近的文献。如果有把握，可以甚至删除一两个你不想用的派别（要有充分的理由），只保留两、三个派别（也要有充分的理由）继续做完以下工作。</p>
<p>　　然后你应该利用（2C）的答案，再进一步回答一个问题（2D）：「这个领域内大家认为重要的关键问题有哪些？有哪些特性是大家重视的优点？有哪些特性是大家在意的缺点？这些优点与缺点通常在哪些应用场合时会比较被重视？在哪些应用场合时比较不会被重视？」然后，你就可以整理出这个领域（研究题目）主要的应用场合，以及这些应用场合上该注意的事项。</p>
<p>　　最后，在你真正开始念论文的 main body 之前，你应该要先根据（2A）和（2C的答案，把各派别内的论文整理在同一个档案夹里，并照时间先后次序排好。然后依照这些派别与你的研究方向的关系远近，一个派别一个派别地逐一把各派一次念完一派的 main bodies。</p>
<p>  <strong>（3）Main body</strong>（含simulation and/or experimental examples）：</p>
<p>　　在你第一次有系统地念某派别的论文 main bodies 时，你只需要念懂：（3A）这篇论文的主要假设是什么（在什么条件下它是有效的），并且评估一下这些假设在现实条件下有多容易（或多难）成立。愈难成立的假设，愈不好用，参考价值也愈低。（3B）在这些假设下，这篇论文主要有什么好处。（3C）这些好处主要表现在哪些公式的哪些项目的简化上。至于整篇论文详细的推导过程，你不需要懂。除了三、五个关键的公式（最后在应用上要使用的公式，你可以从这里评估出这个方法使用上的方便程度或计算效率，以及在非理想情境下这些公式使用起来的可靠度或稳定性）之外，其它公式都不懂也没关系，公式之间的恒等式推导过程可以完全略过去。假如你要看公式，重点是看公式推导过程中引入的假设条件，而不是恒等式的转换。</p>
<p>但是，在你开始根据前述问题念论文之前，你应该先把这派别所有的论文都拿出来，逐篇粗略地浏览过去（不要勉强自己每篇或每行都弄到懂，而是轻松地读，能懂就懂，不懂就不懂），从中挑出容易念懂的 papers，以及经常被引述的论文。然后把这些论文照时间先后次序依序念下去。记得：你念的时候只要回答（3A）、（ 3B）、（3C）三个问题就好，不要念太细。</p>
<p>　　这样念完以后，你应该把这一派的主要发展过程，主要假设、主要理论依据、以及主要的成果做一个完整的整理。其次，你还要在根据（2D）的答案以及这一派的主要假设，进一步回答下一个问题：（3D）这一派主要的缺点有哪些。最后，根据（ 3A）、（3B）、（3C）、（3D）的答案综合整理出：这一派最适合什么时候使用，最不适合什么场合使用。</p>
<p>　　记住：回答完这些问题时，你还是不应该知道恒等式是怎么导出来的！</p>
<p>　　当你是生手的时候，你要评估一个方法的优缺点时，往往必须要参考它Examples。但是，要记得：老练的论文写作高手会故意只 present 成功的案例而遮掩失败的案例。所以，simulation examples and/or experiments 很棒不一定表示这方法真的很好。你必须要回到这个方法的基本假设上去，以及他在应用时所使用的主要公式（resultant equations）去，凭自己的思考能力， 并且参考（2C）和（2D）的答案，自己问问看：当某某假设在某些实用场合上无法成立时，这个方法会不会出什么状况？猜一猜，预测一下这个方法应该会在哪些条件下（应用场合）表现优异，又会在哪些条件下（应用场合）出状况？根据这个猜测再检验一次simulation examples and/or experiments，看它的长处与短处是不是确实在这些examples 中充分被检验，且充分表现出来。</p>
<p>　　那么，你什么时候才需要弄懂一篇论文所有的恒等式推导过程，或者把整篇论文细细读完？NEVER！你只需要把确定会用到的部分给完全搞懂就好，不确定会不会用到的部分，只需要了解它主要的点子就够了。</p>
<p>　　硕士生和大学生最主要的差别：大学生读什么都必须要从头到尾都懂，硕士生只需要懂他用得着的部分就好了！大学生因为面对的知识是有固定的范围，所以他那样念。硕士生面对的知识是没有范围的，因此他只需要懂他所需要的细腻度就够了。硕士生必须学会选择性的阅读，而且必须锻炼出他选择时的准确度以及选择的速度，不要浪费时间在学用不着的细节知识！多吸收「点子」比较重要，而不是细部的知识。</p>
<p><img src="http://i.imgur.com/zaBbrg4.jpg" alt=""></p>
<p><img src="http://i.imgur.com/yc6w5yv.jpg" alt=""></p>
<h1 id="五、方法与应用场合特性表（有迹可寻的创意程序）"><a href="#五、方法与应用场合特性表（有迹可寻的创意程序）" class="headerlink" title="五、方法与应用场合特性表（有迹可寻的创意程序）"></a>五、方法与应用场合特性表（有迹可寻的创意程序）</h1><p>　　试着想象说你从上图中论文阅读步骤的第（4）与（5）步骤分别获得以下两张表：譬如，当你的题目是「如何标定fiducial mark 之中心位置」，你就必须要仔细搜寻出文献上所有可能可以用来做这一个工作的方法。或许你找到的方法一共有四种，依序如下。譬如（随便乱举例），「方法一」可能表示：「以面积形心标定 fiducial mark 之中心位置」，「方法二」可能表示「以 Hugh transform标定 fiducial mark 之中心位置」，「方法三」可能表示：「以局部弧形 matching 的方法标定fiducial mark 之中心位置」，「方法四」可能表示：「以 ring code标定fiducial mark 之中心位置」。</p>
<p>　　这些方法各有它的特色（优缺点），譬如（随便乱举例），特性1可能表示「计算速度」（因此，根据上表左边第一个 row，可以发现：方法一的计算速度很快，方法二与方法三的计算速度很慢，而方法四的计算速度普通。其次，特性2可能代表「光源亮度不稳定时计算位置的误差大小」，特性3可能代表「噪声对计算出的位置干扰多大」，特性4可能代表「图形边缘有破损时计算的可靠度」，特性5可能代表「对象有彼此的遮蔽时方法的适用性」等等。所以，以上左图中第五个row为例，可以发现：当对象有彼此的遮蔽时，除方法二之外其它三个方法的适用性都很好。</p>
<p>　　但是，同样一个方法可能有许多不同的应用场合，而不同应用场合可能会对适用（或最佳）的方法有不同要求。所以，让我们来看右边的「问题特性分析表」。譬如（随便乱举例），应用甲可能是「标定fiducial mark 之中心位置」的方法在「电路插件组装（SMT）」里的应用，应用乙可能是「标定fiducial mark 之中心位置」的方法在「生物检验自动化影像处理」里的应用，而应用丙则可能是「标定 fiducial mark 之中心位置」的方法在「巡乂飞弹目标搜寻」里的应用。这三种应用场合更有其关注的特性。譬如，根据上面右表第二个 row 的资料，三种应用场合对特性2（光源亮度不稳定时计算位置的误差大小）都很在意。再譬如，根据上面右表第四个 row 的资料，三种应用场合中除了应用甲（电路插件组装（SMT））之外，其它两种应用场合对特性4（图形边缘有破损时计算的可靠度）都很在意。</p>
<p>　　那么，四个方法中哪个方法最好？你可能会回答说：「方法二！因为它的优点最多，缺点最少。」但是，这样的回答是错的！一个方法只有优缺点，而没有好坏。当它被用在一个适合表现其优点而不在乎其缺点的场合里，它就显得很好；但是，当它被用在一个不适合表现其优点而很在乎其缺点的场合里，它就显得很糟。譬如，方法二在应用场合乙，它的表现会非常出色（因为所有的优点刚好那个应用场合都在意，而所有的缺点刚好那个应用场合都不在意）；但是，方法二在应用场合甲里它的表现却会非常糟糕（它所有的缺点刚好那个应用场合都很在意，而它大部分的优点刚好那个应用场合却都不在意）。所以，必须要学会的第一件是就是：方法没有好坏，只有相对优缺点点；只有当方法的特性与应用场合的特性不合时，才能下结论说这方法「不适用」；二当当方法的特性与应用场合的特性吻合时，则下结论说这方法「很适用」。因此，一定要同时有方法特性表与应用场合特性分析表放在一起后，才能判断一个方法的适用性。</p>
<p>　　更重要的是：上面的方法与问题分析对照表还可以用来把「突破瓶颈所需的创意」简化成一种「有迹可寻」的工作。譬如，假定我们要针对应用甲发展一套适用的方法，首先我们要先从上右表中标定这个应用场合关心哪些问题特性。根据上右表第一个 column，甲应用场合只关心四个特性：特性1、2、3、5（即「计算速度」、「光源亮度不稳定时计算位置的误差大小」、「噪声对计算出的位置的干扰」、「对象有彼此的遮蔽时方法的适用性」）。那么，哪个方法最适用呢？看起来是方法</p>
<p>　　一，它除了特性2表现普通之外，其它三个特性的表现都很出色。但是，假如我们对方法一的表现仍不够满意，怎么去改善它？最简单的办法就是从上左表找现成的方法和方法一结合，产生出一个更适用的方法。因为方法一只有在特性2上面表现不够令人满意，所以我们就优先针对在特性2上面表现出色的其它方法加以研究。根据上左表，在特性2上面表现出色的方法有方法二和方法四，所以我们就去研究这两个方法和方法一结合的可能性。或许（随便举例）方法四的创意刚好可以被结合进方法一而改善方法一在特性2上面的表现，那么，我们就可以因此轻易地获得一个方法一的改良，从而突破甲应用场合没有适用方法的瓶颈。</p>
<p>　　有没有可能说单纯常识结合既有方法优点仍无法突破技术瓶颈的状况？可能有。这时候真的需要完全新颖的创意了。但是，这种时候很罕见。多半时候只要应用上一段的分析技巧就可以产生足以解决实用问题的创意了。至少，要产生出一篇学术期刊论文并非那么困难。</p>
<h1 id="六、论文阅读的补充说明"><a href="#六、论文阅读的补充说明" class="headerlink" title="六、论文阅读的补充说明"></a>六、论文阅读的补充说明</h1><p>　　硕士生开始学读期刊论文时，就容易犯的毛病就是戒除不掉大学部的习惯：（1）老是想逐行读懂，有一行读不懂就受不了。（2）不敢发挥自己的想象，读论文像在读教科书，论文没写的就不会，瘫痪在那里；被我逼着去自己猜测或想象时，老怕弄错作者的意思，神经绷紧，脑筋根本动不了。</p>
<p>　　大学毕业后（不管是念硕、博士或工作），可以参考的资料都没有秩序地交错成一团，而且永远都读不完。用大学生的心态读书，结果一定时间永远不够用。因此，每次读论文都一定要带着问题去读，每次读的时候都只是图回答你要回答的问题。因此，一定是选择性地阅读，一定要逐渐由粗而细地一层一层去了解。上面所规划的读论文的次序，就是由粗而细，每读完一轮，你对这问题的知识就增加一层。根据这一层知识就可以问出下一层更细致的问题，再根据这些更细致的问题去重读，就可以理解到更多的内容。因此，一定是一整批一起读懂到某个层次，而不是逐篇逐篇地整篇一次读懂。</p>
<p>　　这样读还有一个好处：第一轮读完后，可以根据第一轮所获得的知识判断出哪些论文与你的议题不相关，不相关的就不需要再读下去了。这样才可以从广泛的论文里逐层准确地筛选出你真正非懂不可的部分。不要读不会用到的东西，白费的力气必须被极小化！其实，绝大部分论文都只需要了解它的主要观念（这往往比较容易），而不需要了解它的详细推导过程（这反而比较费时）。</p>
<p>　　其次，一整批一起读还有一个好处：同一派的观念，有的作者说得较易懂，有的说得不清楚。整批读略过一次之后，就可以规划出一个你以为比较容易懂的阅读次序，而不要硬碰硬地在那里撞墙壁。你可以从甲论文帮你弄懂以论文的一个段落，没人说读懂甲论文只能靠甲论文的信息。所以，整批阅读很像在玩跳棋，你要去规划出你自己阅读时的「最省力路径」。</p>
<p>　　大学部学生读东西一定要循规蹈矩，你还没修过机械视觉相关课程之前可能也只好循规蹈矩地逐行去念。但是一旦修过机械视觉相关课程，许多论文中没被交代的段落你也已经可以有一些属于你的想象（虽然有可能猜错，尤其刚开始时经常猜错，但没关系，下面详述）。这些想象往往补足论文跳跃处最快速的解决方案。其实，一个大学毕业生所学已经很多了，对许多是都可以有一个不太离谱的想象能力。但是大部分学生却根本不敢去想象。我读论文远比学生快，分析远比学生深入，主要的是我敢想象与猜测，而且多年训练下来想象与猜测的准确度很高。所以，许多论文我根本不是「读懂」的，而是「猜对」了！</p>
<p>　　假如猜错了怎么办？不用怕！猜完一后要根据你的猜测在论文里找证据，用以判断你的猜测对不对。猜对了，就用你的猜测（其实是你的推理架构）去吸收作者的资讯与创意（这会比从头硬生生地去迁就作者的思路轻松而容易）；猜错了，论文理会有一些信息告诉你说你错了，而且因为猜错所以你读到对的答案时反而印象更深刻。</p>
<h1 id="七、论文报告的要求与技巧"><a href="#七、论文报告的要求与技巧" class="headerlink" title="七、论文报告的要求与技巧"></a>七、论文报告的要求与技巧</h1><p>　　报告一篇论文，我要求做到以下部分（依报告次序排列）：</p>
<p>　　（1） 投影片第一页必须列出论文的题目、作者、论文出处与年份。</p>
<p>　　（2） 以下每一页投影片只能讲一个观念，不可以在一张投影片里讲两个观念。</p>
<p>　　（3） 说明这篇论文所研究的问题的重点，以及这个问题可能和工业界的哪些应用相关。</p>
<p>　　（4） 清楚交代这篇论文的主要假设，主要公式，与主要应用方式（以及应用上可能的解题流程）。</p>
<p>　　（5） 说明这篇论文的范例（simulation examples and/or experiments），预测这个方法在不同场合时可能会有的准确度或好用的程度</p>
<p>　　（6） 你个人的分析、评价与批评，包括：（6A）这篇论文最主要的创意是什么？（6B）这些创意在应用上有什么好处？（6C）这些创意和应用上的好处是在哪些条件下才能成立？（6D）这篇论文最主要的缺点或局限是什么？（6E）这些缺点或局限在应用上有什么坏处？（6F）这些缺点和应用上的坏处是因为哪些因素而引入的？（6G）你建议学长学弟什么时候参考这篇论文的哪些部分（点子）？</p>
<p>　　一般来讲，刚开始报告论文（硕一上学期）时只要做到能把前四项要素说清楚就好了，但是硕一结束后（暑假开始）必须要设法做到六项要素都能触及。硕二下学期开始的时候，必须要做到六项都能说清楚。</p>
<p>　　注意：读论文和报告论文时，最重要的是它的创意和观念架构，而不是数学上恒等式推导过程的细节（顶多只要抓出关键的 equation 去弩懂以及说明清楚即可）。你报告观念与分析创意，别人容易听懂又觉得有趣；你讲恒等式，大家不耐烦又浪费时间。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/07/27/A Complete Tutorial(3)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Andy Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Andy's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/07/27/A Complete Tutorial(3)/" itemprop="url">A Complete Tutorial to Learn Data Science with Python from Scratch(3)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-07-27T00:00:00+08:00">
                2017-07-27
              </time>
            

            

            
          </span>

		  
		  
          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
			
			
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="4-Data-Munging-in-Python-Using-Pandas"><a href="#4-Data-Munging-in-Python-Using-Pandas" class="headerlink" title="4. Data Munging in Python : Using Pandas"></a>4. Data Munging in Python : Using Pandas</h2><p>For those, who have been following, here are your must wear shoes to start running.</p>
<p>Data munging – recap of the need</p>
<p>While our exploration of the data, we found a few problems in the data set, which needs to be solved before the data is ready for a good model. This exercise is typically referred as “Data Munging”. Here are the problems, we are already aware of:</p>
<p>There are missing values in some variables. We should estimate those values wisely depending on the amount of missing values and the expected importance of variables.<br>While looking at the distributions, we saw that ApplicantIncome and LoanAmount seemed to contain extreme values at either end. Though they might make intuitive sense, but should be treated appropriately.<br>In addition to these problems with numerical fields, we should also look at the non-numerical fields i.e. Gender, Property_Area, Married, Education and Dependents to see, if they contain any useful information.</p>
<p>If you are new to Pandas, I would recommend reading <a href="https://www.analyticsvidhya.com/blog/2016/01/12-pandas-techniques-python-data-manipulation/" target="_blank" rel="external">this article(Pandas的12种奇淫异巧)</a> before moving on. It details some useful techniques of data manipulation.</p>
<p><strong>数据修复</strong></p>
<p><img src="http://www.ynfzb.cn/upload/image/201111/20111115141602377484.jpg" alt="数据修复"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">%matplotlib inline</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df=pd.read_csv(<span class="string">"G:/Datahack/Loanprediction/TrainFile/train.csv"</span>) <span class="comment">#读取数据</span></div></pre></td></tr></table></figure>
<h3 id="Check-missing-values-in-the-dataset"><a href="#Check-missing-values-in-the-dataset" class="headerlink" title="Check missing values in the dataset"></a>Check missing values in the dataset</h3><p>Let us look at missing values in all the variables because most of the models don’t work with missing data and even if they do, imputing them helps more often than not. So, let us check the number of nulls / NaNs in the dataset.<br>(检查一下数据集的缺失值)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">df.apply(<span class="keyword">lambda</span> x:sum(x.isnull()),axis=<span class="number">0</span>) <span class="comment"># 匿名函数，axis=0表示针对每列应该用，可以看看</span></div><div class="line"><span class="comment">#与 df.apply(lambda x:sum(x.isnull()),axis=1)的区别</span></div></pre></td></tr></table></figure>
<pre><code>Loan_ID               0
Gender               13
Married               3
Dependents           15
Education             0
Self_Employed        32
ApplicantIncome       0
CoapplicantIncome     0
LoanAmount           22
Loan_Amount_Term     14
Credit_History       50
Property_Area         0
Loan_Status           0
dtype: int64
</code></pre><p>可以看到Gender丢失13个，Married丢失3个，Dependents丢失15个，Self_Employed丢失32个，LoanAmount丢失22个，Loan_Amount_Term丢失14个，Credit_History丢失50个。</p>
<p>Though the missing values are not very high in number, but many variables have them and each one of these should be estimated and added in the data. Get a detailed view on different imputation techniques through <a href="https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/" target="_blank" rel="external">this article(A Comprehensive Guide to Data Exploration)</a>.</p>
<p>Note: Remember that missing values may not always be NaNs. For instance, if the Loan_Amount_Term is 0, does it makes sense or would you consider that missing? I suppose your answer is missing and you’re right. So we should check for values which are unpractical.(值得注意的是，并非所有丢失值都是NaN,也可能是0或者其他不合理的值)</p>
<h3 id="How-to-fill-missing-values-in-LoanAmount"><a href="#How-to-fill-missing-values-in-LoanAmount" class="headerlink" title="How to fill missing values in LoanAmount?"></a>How to fill missing values in LoanAmount?</h3><p>如何填充丢失值是一个问题，下面以LoanAmount为例。</p>
<p>There are numerous ways to fill the missing values of loan amount – the simplest being replacement by mean, which can be done by following code:（最简单的方法，以平均值进行填充）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df[<span class="string">'LoanAmount'</span>].fillna(df[<span class="string">'LoanAmount'</span>].mean(),inplace=<span class="keyword">True</span>)<span class="comment"># 平均值填充</span></div></pre></td></tr></table></figure>
<p>The other extreme could be to build a supervised learning model to predict loan amount on the basis of other variables and then use age along with other variables to predict survival.(另一个方法是建立一个有监督学习模型利用其他变量来预测未知值）</p>
<p>Since, the purpose now is to bring out the steps in data munging, I’ll rather take an approach, which lies some where in between these 2 extremes. A key hypothesis is that the whether a person is educated or self-employed can combine to give a good estimate of loan amount.（但这里只是一个入门教程，采用一种介于上述两种方法之间的手段来填充丢失值）</p>
<p>First, let’s look at the boxplot to see if a trend exists:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df.boxplot(column=<span class="string">'LoanAmount'</span>,by=[<span class="string">'Education'</span>,<span class="string">'Self_Employed'</span>])</div></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x9d956d8&gt;
</code></pre><p><img src="http://i.imgur.com/UBSLV9T.png" alt="picture1"></p>
<p>Thus we see some variations in the median of loan amount for each group and this can be used to impute the values. But first, we have to ensure that each of Self_Employed and Education variables should not have a missing values.(由上面的Boxplot可以看出，不同Education和Self_Employed的组合对LoanAmount的中位数还是有影响的。因此，可以用Education和Self_Employed来进行推断。但在此之前，必须保证Education和Self_Employed是完整的)</p>
<p>As we say earlier, Self_Employed has some missing values. Let’s look at the frequency table:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df[<span class="string">'Self_Employed'</span>].value_counts()</div></pre></td></tr></table></figure>
<pre><code>No     500
Yes     82
Name: Self_Employed, dtype: int64
</code></pre><p>Since ~86% values are “No”, it is safe to impute the missing values as “No” as there is a high probability of success. This can be done using the following code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df[<span class="string">'Self_Employed'</span>].fillna(<span class="string">'No'</span>,inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure>
<p>Now, we will create a Pivot table, which provides us median values for all the groups of unique values of Self_Employed and Education features. Next, we define a function, which returns the values of these cells and apply it to fill the missing values of loan amount:<br>(由Education和Self_Employed两列所确定的LoanAmount的中位数来填充LoanAmount的丢失值)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">table = df.pivot_table(values=<span class="string">'LoanAmount'</span>, index=<span class="string">'Self_Employed'</span> ,</div><div class="line">                       columns=<span class="string">'Education'</span>, aggfunc=np.median)</div><div class="line"><span class="comment"># Define function to return value of this pivot_table</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">fage</span><span class="params">(x)</span>:</span></div><div class="line"> <span class="keyword">return</span> table.loc[x[<span class="string">'Self_Employed'</span>],x[<span class="string">'Education'</span>]]</div><div class="line"><span class="comment"># Replace missing values</span></div><div class="line">df[<span class="string">'LoanAmount'</span>].fillna(df[df[<span class="string">'LoanAmount'</span>].isnull()].apply(fage, axis=<span class="number">1</span>), inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure>
<h3 id="How-to-treat-for-extreme-values-in-distribution-of-LoanAmount-and-ApplicantIncome"><a href="#How-to-treat-for-extreme-values-in-distribution-of-LoanAmount-and-ApplicantIncome" class="headerlink" title="How to treat for extreme values in distribution of LoanAmount and ApplicantIncome ?"></a>How to treat for extreme values in distribution of LoanAmount and ApplicantIncome ?</h3><p>Let’s analyze LoanAmount first. Since the extreme values are practically possible, i.e. some people might apply for high value loans due to specific needs. So instead of treating them as outliers, let’s try a log transformation to nullify their effect:<br>(使用Log函数消除极端值的影响）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">df[<span class="string">'LoanAmount_log'</span>]=np.log(df[<span class="string">'LoanAmount'</span>])</div><div class="line">df[<span class="string">'LoanAmount_log'</span>].hist(bins=<span class="number">20</span>)</div></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x9f000f0&gt;
</code></pre><p><img src="http://i.imgur.com/gBbmlag.png" alt="picture2"></p>
<p>Now the distribution looks much closer to normal and effect of extreme values has been significantly subsided.</p>
<p>Coming to ApplicantIncome. One intuition can be that some applicants have lower income but strong support Co-applicants. So it might be a good idea to combine both incomes as total income and take a log transformation of the same.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">df[<span class="string">'TotalIncome'</span>]=df[<span class="string">'ApplicantIncome'</span>]+df[<span class="string">'CoapplicantIncome'</span>]</div><div class="line">df[<span class="string">'TotalIncome_log'</span>]=np.log(df[<span class="string">'TotalIncome'</span>])</div><div class="line">df[<span class="string">'LoanAmount_log'</span>].hist(bins=<span class="number">20</span>)</div></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0xa007da0&gt;
</code></pre><p><img src="http://i.imgur.com/IPLEAsM.png" alt="picture3"></p>
<p>Now we see that the distribution is much better than before. I will leave it upto you to impute the missing values for Gender, Married, Dependents, Loan_Amount_Term, Credit_History. Also, I encourage you to think about possible additional information which can be derived from the data. For example, creating a column for LoanAmount/TotalIncome might make sense as it gives an idea of how well the applicant is suited to pay back his loan.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df.apply(<span class="keyword">lambda</span> x:sum(x.isnull()),axis=<span class="number">0</span>)</div></pre></td></tr></table></figure>
<pre><code>Loan_ID               0
Gender               13
Married               3
Dependents           15
Education             0
Self_Employed         0
ApplicantIncome       0
CoapplicantIncome     0
LoanAmount            0
Loan_Amount_Term     14
Credit_History       50
Property_Area         0
Loan_Status           0
LoanAmount_log        0
TotalIncome           0
TotalIncome_log       0
dtype: int64
</code></pre><p>丢失的还有Gender,Married,Dependents,Loan_Amount_Term,Credit_History5个。其中Married比较好处理，直接以大多数类别填充，先把它处理啦。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df[<span class="string">'Married'</span>].value_counts()</div></pre></td></tr></table></figure>
<pre><code>Yes    398
No     213
Name: Married, dtype: int64
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df[<span class="string">'Married'</span>].fillna(<span class="string">'Yes'</span>,inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure>
<p>接着处理Gender(性别),缺了13个。直观上，先看看Gender和Married、Education、Self_Employed、Property_Area的关系。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">percConvert</span><span class="params">(ser)</span>:</span></div><div class="line">    <span class="keyword">return</span> ser/float(ser[<span class="number">-1</span>])</div><div class="line"></div><div class="line">pd.crosstab(df[<span class="string">'Married'</span>],df[<span class="string">'Gender'</span>],margins=<span class="keyword">True</span>).apply(percConvert,axis=<span class="number">1</span>)</div></pre></td></tr></table></figure>
<div><br><style><br>    .dataframe thead tr:only-child th {<br>        text-align: right;<br>    }<br><br>    .dataframe thead th {<br>        text-align: left;<br>    }<br><br>    .dataframe tbody tr th {<br>        vertical-align: top;<br>    }<br></style><br><table border="1" class="dataframe"><br>  <thead><br>    <tr style="text-align: right;"><br>      <th>Gender</th><br>      <th>Female</th><br>      <th>Male</th><br>      <th>All</th><br>    </tr><br>    <tr><br>      <th>Married</th><br>      <th></th><br>      <th></th><br>      <th></th><br>    </tr><br>  </thead><br>  <tbody><br>    <tr><br>      <th>No</th><br>      <td>0.380952</td><br>      <td>0.619048</td><br>      <td>1.0</td><br>    </tr><br>    <tr><br>      <th>Yes</th><br>      <td>0.081841</td><br>      <td>0.918159</td><br>      <td>1.0</td><br>    </tr><br>    <tr><br>      <th>All</th><br>      <td>0.186356</td><br>      <td>0.813644</td><br>      <td>1.0</td><br>    </tr><br>  </tbody><br></table><br></div>



<p>上表可以看出已婚人士中，Male占0.918，那假如某人性别未知，只知其已婚，是不是有0.918的概率判断其为男性呢？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pd.crosstab(df[<span class="string">'Education'</span>],df[<span class="string">'Gender'</span>],margins=<span class="keyword">True</span>).apply(percConvert,axis=<span class="number">1</span>)</div></pre></td></tr></table></figure>
<div><br><style><br>    .dataframe thead tr:only-child th {<br>        text-align: right;<br>    }<br><br>    .dataframe thead th {<br>        text-align: left;<br>    }<br><br>    .dataframe tbody tr th {<br>        vertical-align: top;<br>    }<br></style><br><table border="1" class="dataframe"><br>  <thead><br>    <tr style="text-align: right;"><br>      <th>Gender</th><br>      <th>Female</th><br>      <th>Male</th><br>      <th>All</th><br>    </tr><br>    <tr><br>      <th>Education</th><br>      <th></th><br>      <th></th><br>      <th></th><br>    </tr><br>  </thead><br>  <tbody><br>    <tr><br>      <th>Graduate</th><br>      <td>0.196581</td><br>      <td>0.803419</td><br>      <td>1.0</td><br>    </tr><br>    <tr><br>      <th>Not Graduate</th><br>      <td>0.150376</td><br>      <td>0.849624</td><br>      <td>1.0</td><br>    </tr><br>    <tr><br>      <th>All</th><br>      <td>0.186356</td><br>      <td>0.813644</td><br>      <td>1.0</td><br>    </tr><br>  </tbody><br></table><br></div>



<p>上表可以看出性别与其Education关系好像并不大。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pd.crosstab(df[<span class="string">'Self_Employed'</span>],df[<span class="string">'Gender'</span>],margins=<span class="keyword">True</span>).apply(percConvert,axis=<span class="number">1</span>)</div></pre></td></tr></table></figure>
<div><br><style><br>    .dataframe thead tr:only-child th {<br>        text-align: right;<br>    }<br><br>    .dataframe thead th {<br>        text-align: left;<br>    }<br><br>    .dataframe tbody tr th {<br>        vertical-align: top;<br>    }<br></style><br><table border="1" class="dataframe"><br>  <thead><br>    <tr style="text-align: right;"><br>      <th>Gender</th><br>      <th>Female</th><br>      <th>Male</th><br>      <th>All</th><br>    </tr><br>    <tr><br>      <th>Self_Employed</th><br>      <th></th><br>      <th></th><br>      <th></th><br>    </tr><br>  </thead><br>  <tbody><br>    <tr><br>      <th>No</th><br>      <td>0.185468</td><br>      <td>0.814532</td><br>      <td>1.0</td><br>    </tr><br>    <tr><br>      <th>Yes</th><br>      <td>0.192308</td><br>      <td>0.807692</td><br>      <td>1.0</td><br>    </tr><br>    <tr><br>      <th>All</th><br>      <td>0.186356</td><br>      <td>0.813644</td><br>      <td>1.0</td><br>    </tr><br>  </tbody><br></table><br></div>



<p>上表可以看出性别与其Self_Employed关系好像也并不大。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pd.crosstab(df[<span class="string">'Dependents'</span>],df[<span class="string">'Gender'</span>],margins=<span class="keyword">True</span>).apply(percConvert,axis=<span class="number">1</span>)</div></pre></td></tr></table></figure>
<div><br><style><br>    .dataframe thead tr:only-child th {<br>        text-align: right;<br>    }<br><br>    .dataframe thead th {<br>        text-align: left;<br>    }<br><br>    .dataframe tbody tr th {<br>        vertical-align: top;<br>    }<br></style><br><table border="1" class="dataframe"><br>  <thead><br>    <tr style="text-align: right;"><br>      <th>Gender</th><br>      <th>Female</th><br>      <th>Male</th><br>      <th>All</th><br>    </tr><br>    <tr><br>      <th>Dependents</th><br>      <th></th><br>      <th></th><br>      <th></th><br>    </tr><br>  </thead><br>  <tbody><br>    <tr><br>      <th>0</th><br>      <td>0.236686</td><br>      <td>0.763314</td><br>      <td>1.0</td><br>    </tr><br>    <tr><br>      <th>1</th><br>      <td>0.188119</td><br>      <td>0.811881</td><br>      <td>1.0</td><br>    </tr><br>    <tr><br>      <th>2</th><br>      <td>0.070707</td><br>      <td>0.929293</td><br>      <td>1.0</td><br>    </tr><br>    <tr><br>      <th>3+</th><br>      <td>0.062500</td><br>      <td>0.937500</td><br>      <td>1.0</td><br>    </tr><br>    <tr><br>      <th>All</th><br>      <td>0.186007</td><br>      <td>0.813993</td><br>      <td>1.0</td><br>    </tr><br>  </tbody><br></table><br></div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">coding</span><span class="params">(col,codeDict)</span>:</span></div><div class="line">    colCoded=pd.Series(col,copy=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">for</span> key,value <span class="keyword">in</span> codeDict.items():</div><div class="line">        colCoded.replace(key,value,inplace=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">return</span> colCoded</div><div class="line">df[<span class="string">'Gender'</span>]=coding(df[<span class="string">'Gender'</span>],&#123;<span class="string">'Male'</span>:<span class="number">1</span>,<span class="string">'Female'</span>:<span class="number">0</span>&#125;) <span class="comment">#将‘Gender'转换为0,1表示（男士：1，女生：0）</span></div><div class="line">table2=df.pivot_table(values=[<span class="string">'Gender'</span>],index=[<span class="string">'Married'</span>,<span class="string">'Dependents'</span>],aggfunc=np.median)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#pd.crosstab(df['Married'],df['Dependents'],margins=True).apply(percConvert,axis=1)</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">dependent</span><span class="params">(x)</span>:</span></div><div class="line">    <span class="keyword">if</span> x[<span class="string">'Married'</span>]==<span class="string">'No'</span>:</div><div class="line">        <span class="keyword">return</span> <span class="string">'0'</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> <span class="string">'1'</span></div><div class="line">df[<span class="string">'Dependents'</span>].fillna(df[df[<span class="string">'Dependents'</span>].isnull()].apply(dependent,axis=<span class="number">1</span>),inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Define function to return value of this pivot_table</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">fage</span><span class="params">(x)</span>:</span></div><div class="line">    <span class="keyword">if</span> table2.loc[x[<span class="string">'Married'</span>],x[<span class="string">'Dependents'</span>]].values[<span class="number">0</span>]==<span class="number">1.0</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">1.0</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> <span class="number">0.0</span></div><div class="line"><span class="comment"># Replace missing values</span></div><div class="line">df[<span class="string">'Gender'</span>].fillna(df[df[<span class="string">'Gender'</span>].isnull()].apply(fage, axis=<span class="number">1</span>), inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df.apply(<span class="keyword">lambda</span> x:sum(x.isnull()),axis=<span class="number">0</span>)</div></pre></td></tr></table></figure>
<pre><code>Loan_ID               0
Gender                0
Married               0
Dependents            0
Education             0
Self_Employed         0
ApplicantIncome       0
CoapplicantIncome     0
LoanAmount            0
Loan_Amount_Term     14
Credit_History       50
Property_Area         0
Loan_Status           0
LoanAmount_log        0
TotalIncome           0
TotalIncome_log       0
dtype: int64
</code></pre><p>可以看到只剩下Loan_Amount_Term和Credit_History没有处理啦，因为Credit_History由前面分析，对于结果来说是非常重要的，那么就放在最后处理好了。现在来对Loan_Amount_Term进行分析，Loan_Amount_Term是数值型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df.boxplot(column=<span class="string">'Loan_Amount_Term'</span>,by=[<span class="string">'Education'</span>,<span class="string">'Self_Employed'</span>])</div></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0xbc43d30&gt;
</code></pre><p><img src="http://i.imgur.com/GQjJl4e.png" alt="picture5"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">termMedian=df[<span class="string">'Loan_Amount_Term'</span>].median()</div><div class="line">df[<span class="string">'Loan_Amount_Term'</span>].fillna(termMedian,inplace=<span class="keyword">True</span>)<span class="comment">#直接由中位数填充好了……</span></div></pre></td></tr></table></figure>
<p>按理说，Credit_History应该是根据一个人的性别，婚姻，家属，教育等申请之前的状态有很大关系，而与当前该次申请贷款的数额、期限等业务关系不大。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df.info()</div></pre></td></tr></table></figure>
<pre><code>&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;
RangeIndex: 614 entries, 0 to 613
Data columns (total 17 columns):
Loan_ID                   614 non-null object
Gender                    614 non-null float64
Married                   614 non-null object
Dependents                614 non-null object
Education                 614 non-null object
Self_Employed             614 non-null object
ApplicantIncome           614 non-null int64
CoapplicantIncome         614 non-null float64
LoanAmount                614 non-null float64
Loan_Amount_Term          614 non-null object
Credit_History            564 non-null float64
Property_Area             614 non-null object
Loan_Status               614 non-null object
LoanAmount_log            614 non-null float64
TotalIncome               614 non-null float64
TotalIncome_log           614 non-null float64
LoanAmount/TotalIncome    614 non-null float64
dtypes: float64(8), int64(1), object(8)
memory usage: 81.6+ KB
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</div><div class="line">var_mod=[<span class="string">'Married'</span>,<span class="string">'Dependents'</span>,<span class="string">'Education'</span>,<span class="string">'Self_Employed'</span>,<span class="string">'Property_Area'</span>,<span class="string">'Loan_Status'</span>]</div><div class="line">le=LabelEncoder()</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> var_mod:</div><div class="line">    df[i]=le.fit_transform(df[i])</div><div class="line">df.dtypes<span class="comment">#将以上非数值型，转化为数值型量</span></div></pre></td></tr></table></figure>
<pre><code>Loan_ID                    object
Gender                    float64
Married                     int64
Dependents                  int64
Education                   int64
Self_Employed               int64
ApplicantIncome             int64
CoapplicantIncome         float64
LoanAmount                float64
Loan_Amount_Term           object
Credit_History            float64
Property_Area               int64
Loan_Status                 int64
LoanAmount_log            float64
TotalIncome               float64
TotalIncome_log           float64
LoanAmount/TotalIncome    float64
dtype: object
</code></pre><h2 id="5-Building-a-Predictive-Model-in-Python"><a href="#5-Building-a-Predictive-Model-in-Python" class="headerlink" title="5. Building a Predictive Model in Python"></a>5. Building a Predictive Model in Python</h2><p>After, we have made the data useful for modeling, let’s now look at the python code to create a predictive model on our data set. Skicit-Learn (sklearn) is the most commonly used library in Python for this purpose and we will follow the trail. I encourage you to get a refresher on sklearn through <a href="https://www.analyticsvidhya.com/blog/2015/01/scikit-learn-python-machine-learning-tool/" target="_blank" rel="external">this article</a>.</p>
<p>Next, we will import the required modules. Then we will define a generic classification function, which takes a model as input and determines the Accuracy and Cross-Validation scores. Since this is an introductory article, I will not go into the details of coding. Please refer to <a href="https://www.analyticsvidhya.com/blog/2015/08/common-machine-learning-algorithms/" target="_blank" rel="external">this article</a> for getting details of the algorithms with R and Python codes. Also, it’ll be good to get a refresher on cross-validation through <a href="https://www.analyticsvidhya.com/blog/2015/11/improve-model-performance-cross-validation-in-python-r/" target="_blank" rel="external">this article</a>, as it is a very important measure of power performance.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Import models from scikit learn module:</span></div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</div><div class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</div><div class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier, export_graphviz</div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Generic function for making a classification model and accessing performance:</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">classification_model</span><span class="params">(model,data,predictors,outcome)</span>:</span></div><div class="line">    <span class="comment">#Fit the model:</span></div><div class="line">    model.fit(data[predictors],data[outcome])</div><div class="line">    </div><div class="line">    <span class="comment">#Make predictions on training set:</span></div><div class="line">    predictions=model.predict(data[predictors])</div><div class="line">    </div><div class="line">    <span class="comment">#Print accuracy</span></div><div class="line">    accuracy=metrics.accuracy_score(predictions,data[outcome])</div><div class="line">    print(<span class="string">"Accuracy : %s"</span> % <span class="string">"&#123;0:.3%&#125;"</span>.format(accuracy))</div><div class="line">    </div><div class="line">    <span class="comment">#Perform k-fold cross-validation with 5 folds</span></div><div class="line">    kf=KFold(n_splits=<span class="number">5</span>).split(data)</div><div class="line">    error=[]</div><div class="line">    <span class="keyword">for</span> train,test <span class="keyword">in</span> kf:</div><div class="line">        <span class="comment">#Filter training data</span></div><div class="line">        train_predictors=(data[predictors].iloc[train,:])</div><div class="line">        </div><div class="line">        <span class="comment">#The target we're using to train the algorithm.</span></div><div class="line">        train_target=data[outcome].iloc[train]</div><div class="line">        </div><div class="line">        <span class="comment">#Training the algorithm using the predictors and target.</span></div><div class="line">        model.fit(train_predictors,train_target)</div><div class="line">        </div><div class="line">        <span class="comment">#Record error from each cross-validation run</span></div><div class="line">        error.append(model.score(data[predictors].iloc[test,:],data[outcome].iloc[test]))</div><div class="line">    </div><div class="line">    print(<span class="string">"Cross-Validation Score : %s"</span> % <span class="string">"&#123;0:.3%&#125;"</span>.format(np.mean(error)))</div><div class="line">    </div><div class="line">    <span class="comment">#Fit the model again so that it can be refered outside the function:</span></div><div class="line">    model.fit(data[predictors],data[outcome])</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">creditTrain=df[df[<span class="string">'Credit_History'</span>].notnull()] <span class="comment">#以Credit_History为输出进行预测</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">outcome_var=<span class="string">'Credit_History'</span></div><div class="line">model=LogisticRegression()<span class="comment">#模型选用普通的线性回归</span></div><div class="line">predictor_var=[<span class="string">'Gender'</span>,<span class="string">'Married'</span>,<span class="string">'Education'</span>,<span class="string">'TotalIncome'</span>]</div><div class="line">classification_model(model,creditTrain,predictor_var,outcome_var)</div></pre></td></tr></table></figure>
<pre><code>Accuracy : 84.220%
Cross-Validation Score : 84.218%
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">outcome_var=<span class="string">'Credit_History'</span></div><div class="line">model=DecisionTreeClassifier()<span class="comment">#模型改为决策树</span></div><div class="line">predictor_var=[<span class="string">'Gender'</span>,<span class="string">'Married'</span>,<span class="string">'Education'</span>,<span class="string">'TotalIncome'</span>]</div><div class="line">classification_model(model,creditTrain,predictor_var,outcome_var)</div></pre></td></tr></table></figure>
<pre><code>Accuracy : 99.113%
Cross-Validation Score : 74.651%
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">outcome_var=<span class="string">'Credit_History'</span></div><div class="line">model=RandomForestClassifier(n_estimators=<span class="number">25</span>,min_samples_split=<span class="number">25</span>,max_depth=<span class="number">7</span>,max_features=<span class="number">1</span>)<span class="comment">#模型改为Random Forest</span></div><div class="line">predictor_var=[<span class="string">'Gender'</span>,<span class="string">'Married'</span>,<span class="string">'Education'</span>,<span class="string">'TotalIncome'</span>]</div><div class="line">classification_model(model,creditTrain,predictor_var,outcome_var)</div></pre></td></tr></table></figure>
<pre><code>Accuracy : 84.929%
Cross-Validation Score : 83.864%
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">creditTest=df[df[<span class="string">'Credit_History'</span>].isnull()]<span class="comment">#以Credit_History丢失值作为测试集，进行预测填充丢失值</span></div><div class="line">creditPredictions=model.predict(creditTest[predictor_var])</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df.loc[df[<span class="string">'Credit_History'</span>].isnull(),<span class="string">'Credit_History'</span>]=creditPredictions <span class="comment">#以预测值进行填充</span></div></pre></td></tr></table></figure>
<h3 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h3><p>Let’s make our first Logistic Regression model. One way would be to take all the variables into the model but this might result in overfitting (don’t worry if you’re unaware of this terminology yet). In simple words, taking all variables might result in the model understanding complex relations specific to the data and will not generalize well. Read more about <a href="https://www.analyticsvidhya.com/blog/2015/11/beginners-guide-on-logistic-regression-in-r/" target="_blank" rel="external">Logistic Regression</a>.</p>
<p>We can easily make some intuitive hypothesis to set the ball rolling. The chances of getting a loan will be higher for:</p>
<ul>
<li>Applicants having a credit history (remember we observed this in exploration?)</li>
<li>Applicants with higher applicant and co-applicant incomes</li>
<li>Applicants with higher education level</li>
<li>Properties in urban areas with high growth perspectives</li>
</ul>
<p>So let’s make our first model with ‘Credit_History’.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">outcome_var=<span class="string">'Loan_Status'</span></div><div class="line">model=LogisticRegression()</div><div class="line">predictor_var=[<span class="string">'Credit_History'</span>]<span class="comment">#仅仅使用一个特征来预测</span></div><div class="line">classification_model(model,df,predictor_var,outcome_var)</div></pre></td></tr></table></figure>
<pre><code>Accuracy : 80.945%
Cross-Validation Score : 80.946%
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#再加上一些特征</span></div><div class="line">predictor_var=[<span class="string">'Credit_History'</span>,<span class="string">'Education'</span>,<span class="string">'Married'</span>,<span class="string">'Self_Employed'</span>,<span class="string">'Property_Area'</span>,<span class="string">'LoanAmount/TotalIncome'</span>]</div><div class="line">classification_model(model,df,predictor_var,outcome_var)</div></pre></td></tr></table></figure>
<pre><code>Accuracy : 80.945%
Cross-Validation Score : 80.946%
</code></pre><p>Generally we expect the accuracy to increase on adding variables. But this is a more challenging case. The accuracy and cross-validation score are not getting impacted by less important variables. Credit_History is dominating the mode. We have two options now:(可以看到使用线性回归方法，在增加更多特征的时候，预测效果并没有很好改变，几乎和原来一样。这时候就需要考虑以下两种方法。）</p>
<ul>
<li>Feature Engineering: dereive new information and try to predict those. I will leave this to your creativity.</li>
<li>Better modeling techniques. Let’s explore this next.</li>
</ul>
<h3 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h3><p>Decision tree is another method for making a predictive model. It is known to provide higher accuracy than logistic regression model. Read more about <a href="https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/" target="_blank" rel="external">Decision Trees</a>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">model=DecisionTreeClassifier()<span class="comment">#换模型</span></div><div class="line">predictor_var=[<span class="string">'Credit_History'</span>,<span class="string">'Gender'</span>,<span class="string">'Married'</span>,<span class="string">'Education'</span>]</div><div class="line">classification_model(model,df,predictor_var,outcome_var)</div></pre></td></tr></table></figure>
<pre><code>Accuracy : 80.945%
Cross-Validation Score : 80.946%
</code></pre><p>Here the model based on categorical variables is unable to have an impact because Credit History is dominating over them. Let’s try a few numerical variables:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">predictor_var=[<span class="string">'Credit_History'</span>,<span class="string">'Loan_Amount_Term'</span>,<span class="string">'LoanAmount_log'</span>]</div><div class="line">classification_model(model,df,predictor_var,outcome_var)</div></pre></td></tr></table></figure>
<pre><code>Accuracy : 88.925%
Cross-Validation Score : 69.371%
</code></pre><p>Here we observed that although the accuracy went up on adding variables, the cross-validation error went down. This is the result of model over-fitting the data. Let’s try an even more sophisticated algorithm and see if it helps:</p>
<h3 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a>Random Forest</h3><p>Random forest is another algorithm for solving the classification problem. Read more about <a href="https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/" target="_blank" rel="external">Random Forest</a>.</p>
<p>An advantage with Random Forest is that we can make it work with all the features and it returns a feature importance matrix which can be used to select features.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">model=RandomForestClassifier(n_estimators=<span class="number">100</span>)</div><div class="line">predictor_var=[<span class="string">'Gender'</span>,<span class="string">'Married'</span>,<span class="string">'Dependents'</span>,<span class="string">'Education'</span>,<span class="string">'Self_Employed'</span>,<span class="string">'Loan_Amount_Term'</span>,<span class="string">'Credit_History'</span>,</div><div class="line">              <span class="string">'Property_Area'</span>,<span class="string">'LoanAmount_log'</span>,<span class="string">'TotalIncome_log'</span>,<span class="string">'LoanAmount/TotalIncome'</span>]</div><div class="line">classification_model(model,df,predictor_var,outcome_var)</div></pre></td></tr></table></figure>
<pre><code>Accuracy : 100.000%
Cross-Validation Score : 78.665%
</code></pre><p>Here we see that the accuracy is 100% for the training set(显然过拟合). This is the ultimate case of overfitting and can be resolved in two ways:</p>
<ul>
<li>Reducing the number of predictors</li>
<li>Tuning the model parameters</li>
</ul>
<p>Let’s try both of these. First we see the feature importance matrix from which we’ll take the most important features.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Create a series with feature importances:</span></div><div class="line">featimp=pd.Series(model.feature_importances_,index=predictor_var).sort_values(ascending=<span class="keyword">False</span>)</div><div class="line">print(featimp)</div></pre></td></tr></table></figure>
<pre><code>Credit_History            0.263870
LoanAmount/TotalIncome    0.192546
TotalIncome_log           0.182355
LoanAmount_log            0.164331
Property_Area             0.041543
Dependents                0.041328
Loan_Amount_Term          0.035326
Married                   0.023571
Gender                    0.019269
Education                 0.018238
Self_Employed             0.017623
dtype: float64
</code></pre><p>Let’s use the top 6 variables for creating a model. Also, we will modify the parameters of random forest model a little bit:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">model=RandomForestClassifier(n_estimators=<span class="number">25</span>,min_samples_split=<span class="number">25</span>,max_depth=<span class="number">7</span>,max_features=<span class="number">1</span>)</div><div class="line">predictor_var=[<span class="string">'TotalIncome_log'</span>,<span class="string">'LoanAmount_log'</span>,<span class="string">'Credit_History'</span>,<span class="string">'LoanAmount/TotalIncome'</span>,<span class="string">'Property_Area'</span>,</div><div class="line">              <span class="string">'Dependents'</span>]</div><div class="line">classification_model(model,df,predictor_var,outcome_var)</div></pre></td></tr></table></figure>
<pre><code>Accuracy : 83.550%
Cross-Validation Score : 80.782%
</code></pre><p>Notice that although accuracy reduced, but the cross-validation score is improving showing that the model is generalizing well. Remember that random forest models are not exactly repeatable. Different runs will result in slight variations because of randomization. But the output should stay in the ballpark.</p>
<p>You would have noticed that even after some basic parameter tuning on random forest, we have reached a cross-validation accuracy only slightly better than the original logistic regression model. This exercise gives us some very interesting and unique learning:</p>
<ol>
<li>Using a more sophisticated model does not guarantee better results.</li>
<li>Avoid using complex modeling techniques as a black box without understanding the underlying concepts. Doing so would increase the tendency of overfitting thus making your models less interpretable</li>
<li>Feature Engineering is the key to success. Everyone can use an Xgboost models but the real art and creativity lies in enhancing your features to better suit the model.</li>
</ol>
<p>So are you ready to take on the challenge? Start your data science journey with Loan Prediction Problem.</p>
<p><a href="https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/" target="_blank" rel="external">参考文章：</a><br><a href="https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/" title="参考链接" target="_blank" rel="external">https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="Andy Chen" />
          <p class="site-author-name" itemprop="name">Andy Chen</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">22</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">14</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">17</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/Andy1314Chen" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.jianshu.com" target="_blank" title="简书">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  简书
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Andy Chen</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

  |  本页点击 <span id="busuanzi_value_page_pv"></span> 次
  |  本站总点击 <span id="busuanzi_value_site_pv"></span> 次
  |  您是第 <span id="busuanzi_value_site_uv"></span> 位访客
<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>



        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.1"></script>



  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  






  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  

  

  
  <script type="text/javascript" src="/js/src/particle.js" count="50" zindex="-2" opacity="1" color="0,104,183"></script>
  <!-- 小红心 -->
  <script type="text/javascript" src="/js/src/love.js"></script>
</body>
</html>
